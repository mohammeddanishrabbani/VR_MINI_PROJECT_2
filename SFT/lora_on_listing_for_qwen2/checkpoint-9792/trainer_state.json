{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2574267837425732,
  "eval_steps": 500,
  "global_step": 9792,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.000841263999158736,
      "grad_norm": 1.1665453910827637,
      "learning_rate": 0.00019986327303323517,
      "loss": 2.1433,
      "step": 32
    },
    {
      "epoch": 0.001682527998317472,
      "grad_norm": 0.24424776434898376,
      "learning_rate": 0.00019969499368952462,
      "loss": 0.5143,
      "step": 64
    },
    {
      "epoch": 0.002523791997476208,
      "grad_norm": 0.2566920220851898,
      "learning_rate": 0.00019952671434581408,
      "loss": 0.3423,
      "step": 96
    },
    {
      "epoch": 0.003365055996634944,
      "grad_norm": 0.35209140181541443,
      "learning_rate": 0.0001993584350021035,
      "loss": 0.3389,
      "step": 128
    },
    {
      "epoch": 0.00420631999579368,
      "grad_norm": 0.3180358409881592,
      "learning_rate": 0.00019919015565839294,
      "loss": 0.3257,
      "step": 160
    },
    {
      "epoch": 0.005047583994952416,
      "grad_norm": 0.3464523255825043,
      "learning_rate": 0.00019902187631468238,
      "loss": 0.3239,
      "step": 192
    },
    {
      "epoch": 0.005888847994111152,
      "grad_norm": 0.3099232614040375,
      "learning_rate": 0.00019885359697097184,
      "loss": 0.3002,
      "step": 224
    },
    {
      "epoch": 0.006730111993269888,
      "grad_norm": 0.34889936447143555,
      "learning_rate": 0.00019868531762726126,
      "loss": 0.3013,
      "step": 256
    },
    {
      "epoch": 0.007571375992428624,
      "grad_norm": 0.3850667178630829,
      "learning_rate": 0.0001985170382835507,
      "loss": 0.3003,
      "step": 288
    },
    {
      "epoch": 0.00841263999158736,
      "grad_norm": 0.3981349766254425,
      "learning_rate": 0.00019834875893984016,
      "loss": 0.3037,
      "step": 320
    },
    {
      "epoch": 0.009253903990746095,
      "grad_norm": 0.30748066306114197,
      "learning_rate": 0.00019818047959612958,
      "loss": 0.2986,
      "step": 352
    },
    {
      "epoch": 0.010095167989904832,
      "grad_norm": 0.33684661984443665,
      "learning_rate": 0.00019801220025241902,
      "loss": 0.2877,
      "step": 384
    },
    {
      "epoch": 0.010936431989063569,
      "grad_norm": 0.44142410159111023,
      "learning_rate": 0.00019784392090870846,
      "loss": 0.2905,
      "step": 416
    },
    {
      "epoch": 0.011777695988222304,
      "grad_norm": 0.3380853831768036,
      "learning_rate": 0.00019767564156499793,
      "loss": 0.2863,
      "step": 448
    },
    {
      "epoch": 0.01261895998738104,
      "grad_norm": 0.34462597966194153,
      "learning_rate": 0.00019750736222128734,
      "loss": 0.2946,
      "step": 480
    },
    {
      "epoch": 0.013460223986539776,
      "grad_norm": 0.391391396522522,
      "learning_rate": 0.00019733908287757678,
      "loss": 0.291,
      "step": 512
    },
    {
      "epoch": 0.014301487985698512,
      "grad_norm": 0.3523242771625519,
      "learning_rate": 0.00019717080353386622,
      "loss": 0.28,
      "step": 544
    },
    {
      "epoch": 0.015142751984857247,
      "grad_norm": 0.3517320454120636,
      "learning_rate": 0.00019700252419015566,
      "loss": 0.28,
      "step": 576
    },
    {
      "epoch": 0.015984015984015984,
      "grad_norm": 0.379398375749588,
      "learning_rate": 0.0001968342448464451,
      "loss": 0.2745,
      "step": 608
    },
    {
      "epoch": 0.01682527998317472,
      "grad_norm": 0.39154696464538574,
      "learning_rate": 0.00019666596550273454,
      "loss": 0.2699,
      "step": 640
    },
    {
      "epoch": 0.017666543982333457,
      "grad_norm": 0.4394533336162567,
      "learning_rate": 0.000196497686159024,
      "loss": 0.2818,
      "step": 672
    },
    {
      "epoch": 0.01850780798149219,
      "grad_norm": 0.3295714855194092,
      "learning_rate": 0.00019632940681531342,
      "loss": 0.2794,
      "step": 704
    },
    {
      "epoch": 0.019349071980650927,
      "grad_norm": 0.4003896117210388,
      "learning_rate": 0.00019616112747160286,
      "loss": 0.2845,
      "step": 736
    },
    {
      "epoch": 0.020190335979809664,
      "grad_norm": 0.3767087757587433,
      "learning_rate": 0.0001959928481278923,
      "loss": 0.2742,
      "step": 768
    },
    {
      "epoch": 0.0210315999789684,
      "grad_norm": 0.3429546356201172,
      "learning_rate": 0.00019582456878418177,
      "loss": 0.2817,
      "step": 800
    },
    {
      "epoch": 0.021872863978127138,
      "grad_norm": 0.42433175444602966,
      "learning_rate": 0.00019565628944047118,
      "loss": 0.2839,
      "step": 832
    },
    {
      "epoch": 0.02271412797728587,
      "grad_norm": 0.3388204276561737,
      "learning_rate": 0.00019548801009676062,
      "loss": 0.2704,
      "step": 864
    },
    {
      "epoch": 0.023555391976444608,
      "grad_norm": 0.3573547303676605,
      "learning_rate": 0.0001953197307530501,
      "loss": 0.2784,
      "step": 896
    },
    {
      "epoch": 0.024396655975603344,
      "grad_norm": 0.3088783323764801,
      "learning_rate": 0.0001951514514093395,
      "loss": 0.2813,
      "step": 928
    },
    {
      "epoch": 0.02523791997476208,
      "grad_norm": 0.3223765790462494,
      "learning_rate": 0.00019498317206562894,
      "loss": 0.2705,
      "step": 960
    },
    {
      "epoch": 0.026079183973920814,
      "grad_norm": 0.4583047032356262,
      "learning_rate": 0.00019481489272191838,
      "loss": 0.2644,
      "step": 992
    },
    {
      "epoch": 0.02692044797307955,
      "grad_norm": 0.3745827376842499,
      "learning_rate": 0.00019464661337820785,
      "loss": 0.2672,
      "step": 1024
    },
    {
      "epoch": 0.027761711972238288,
      "grad_norm": 0.39367052912712097,
      "learning_rate": 0.00019447833403449726,
      "loss": 0.2753,
      "step": 1056
    },
    {
      "epoch": 0.028602975971397025,
      "grad_norm": 0.3609001636505127,
      "learning_rate": 0.0001943100546907867,
      "loss": 0.2672,
      "step": 1088
    },
    {
      "epoch": 0.02944423997055576,
      "grad_norm": 0.34311509132385254,
      "learning_rate": 0.00019414177534707617,
      "loss": 0.2584,
      "step": 1120
    },
    {
      "epoch": 0.030285503969714495,
      "grad_norm": 0.3580423891544342,
      "learning_rate": 0.0001939734960033656,
      "loss": 0.2646,
      "step": 1152
    },
    {
      "epoch": 0.03112676796887323,
      "grad_norm": 0.3460373282432556,
      "learning_rate": 0.00019380521665965503,
      "loss": 0.2689,
      "step": 1184
    },
    {
      "epoch": 0.03196803196803197,
      "grad_norm": 0.43884938955307007,
      "learning_rate": 0.00019363693731594447,
      "loss": 0.27,
      "step": 1216
    },
    {
      "epoch": 0.032809295967190705,
      "grad_norm": 0.34673938155174255,
      "learning_rate": 0.00019346865797223393,
      "loss": 0.2701,
      "step": 1248
    },
    {
      "epoch": 0.03365055996634944,
      "grad_norm": 0.3517928123474121,
      "learning_rate": 0.00019330037862852335,
      "loss": 0.2581,
      "step": 1280
    },
    {
      "epoch": 0.03449182396550818,
      "grad_norm": 0.36125895380973816,
      "learning_rate": 0.00019313209928481279,
      "loss": 0.2897,
      "step": 1312
    },
    {
      "epoch": 0.035333087964666915,
      "grad_norm": 0.4120945334434509,
      "learning_rate": 0.00019296381994110225,
      "loss": 0.2913,
      "step": 1344
    },
    {
      "epoch": 0.036174351963825645,
      "grad_norm": 0.40672504901885986,
      "learning_rate": 0.0001927955405973917,
      "loss": 0.2818,
      "step": 1376
    },
    {
      "epoch": 0.03701561596298438,
      "grad_norm": 0.4076375365257263,
      "learning_rate": 0.0001926272612536811,
      "loss": 0.3016,
      "step": 1408
    },
    {
      "epoch": 0.03785687996214312,
      "grad_norm": 0.36356794834136963,
      "learning_rate": 0.00019245898190997055,
      "loss": 0.2808,
      "step": 1440
    },
    {
      "epoch": 0.038698143961301855,
      "grad_norm": 0.45247799158096313,
      "learning_rate": 0.00019229070256626001,
      "loss": 0.2967,
      "step": 1472
    },
    {
      "epoch": 0.03953940796046059,
      "grad_norm": 0.36854231357574463,
      "learning_rate": 0.00019212242322254943,
      "loss": 0.2805,
      "step": 1504
    },
    {
      "epoch": 0.04038067195961933,
      "grad_norm": 0.377217173576355,
      "learning_rate": 0.00019195414387883887,
      "loss": 0.2973,
      "step": 1536
    },
    {
      "epoch": 0.041221935958778065,
      "grad_norm": 0.39315760135650635,
      "learning_rate": 0.00019178586453512834,
      "loss": 0.2923,
      "step": 1568
    },
    {
      "epoch": 0.0420631999579368,
      "grad_norm": 0.3872030973434448,
      "learning_rate": 0.00019161758519141778,
      "loss": 0.2964,
      "step": 1600
    },
    {
      "epoch": 0.04290446395709554,
      "grad_norm": 0.3682553768157959,
      "learning_rate": 0.0001914493058477072,
      "loss": 0.2928,
      "step": 1632
    },
    {
      "epoch": 0.043745727956254275,
      "grad_norm": 0.41323190927505493,
      "learning_rate": 0.00019128102650399663,
      "loss": 0.2854,
      "step": 1664
    },
    {
      "epoch": 0.044586991955413005,
      "grad_norm": 0.39940178394317627,
      "learning_rate": 0.0001911127471602861,
      "loss": 0.2849,
      "step": 1696
    },
    {
      "epoch": 0.04542825595457174,
      "grad_norm": 0.4436747431755066,
      "learning_rate": 0.00019094446781657554,
      "loss": 0.2895,
      "step": 1728
    },
    {
      "epoch": 0.04626951995373048,
      "grad_norm": 0.4146920144557953,
      "learning_rate": 0.00019077618847286495,
      "loss": 0.2926,
      "step": 1760
    },
    {
      "epoch": 0.047110783952889215,
      "grad_norm": 0.46831604838371277,
      "learning_rate": 0.00019060790912915442,
      "loss": 0.282,
      "step": 1792
    },
    {
      "epoch": 0.04795204795204795,
      "grad_norm": 0.3804715871810913,
      "learning_rate": 0.00019043962978544386,
      "loss": 0.2839,
      "step": 1824
    },
    {
      "epoch": 0.04879331195120669,
      "grad_norm": 0.4140132665634155,
      "learning_rate": 0.00019027135044173327,
      "loss": 0.2936,
      "step": 1856
    },
    {
      "epoch": 0.049634575950365425,
      "grad_norm": 0.39991092681884766,
      "learning_rate": 0.0001901030710980227,
      "loss": 0.2886,
      "step": 1888
    },
    {
      "epoch": 0.05047583994952416,
      "grad_norm": 0.4210655093193054,
      "learning_rate": 0.00018993479175431218,
      "loss": 0.2873,
      "step": 1920
    },
    {
      "epoch": 0.0513171039486829,
      "grad_norm": 0.4278472363948822,
      "learning_rate": 0.00018976651241060162,
      "loss": 0.2874,
      "step": 1952
    },
    {
      "epoch": 0.05215836794784163,
      "grad_norm": 0.38785237073898315,
      "learning_rate": 0.00018959823306689103,
      "loss": 0.2826,
      "step": 1984
    },
    {
      "epoch": 0.052999631947000365,
      "grad_norm": 0.39720088243484497,
      "learning_rate": 0.0001894299537231805,
      "loss": 0.2904,
      "step": 2016
    },
    {
      "epoch": 0.0538408959461591,
      "grad_norm": 0.36903998255729675,
      "learning_rate": 0.00018926167437946994,
      "loss": 0.2854,
      "step": 2048
    },
    {
      "epoch": 0.05468215994531784,
      "grad_norm": 0.38046783208847046,
      "learning_rate": 0.00018909339503575938,
      "loss": 0.2766,
      "step": 2080
    },
    {
      "epoch": 0.055523423944476576,
      "grad_norm": 0.3493290841579437,
      "learning_rate": 0.0001889251156920488,
      "loss": 0.2745,
      "step": 2112
    },
    {
      "epoch": 0.05636468794363531,
      "grad_norm": 0.331566721200943,
      "learning_rate": 0.00018875683634833826,
      "loss": 0.286,
      "step": 2144
    },
    {
      "epoch": 0.05720595194279405,
      "grad_norm": 0.4273143708705902,
      "learning_rate": 0.0001885885570046277,
      "loss": 0.2842,
      "step": 2176
    },
    {
      "epoch": 0.058047215941952786,
      "grad_norm": 0.40943431854248047,
      "learning_rate": 0.00018842027766091711,
      "loss": 0.2802,
      "step": 2208
    },
    {
      "epoch": 0.05888847994111152,
      "grad_norm": 0.36975908279418945,
      "learning_rate": 0.00018825199831720655,
      "loss": 0.2752,
      "step": 2240
    },
    {
      "epoch": 0.05972974394027026,
      "grad_norm": 0.38828811049461365,
      "learning_rate": 0.00018808371897349602,
      "loss": 0.2781,
      "step": 2272
    },
    {
      "epoch": 0.06057100793942899,
      "grad_norm": 0.42813703417778015,
      "learning_rate": 0.00018791543962978546,
      "loss": 0.2832,
      "step": 2304
    },
    {
      "epoch": 0.061412271938587726,
      "grad_norm": 0.3777768909931183,
      "learning_rate": 0.00018774716028607488,
      "loss": 0.2764,
      "step": 2336
    },
    {
      "epoch": 0.06225353593774646,
      "grad_norm": 0.4013887345790863,
      "learning_rate": 0.00018757888094236434,
      "loss": 0.2762,
      "step": 2368
    },
    {
      "epoch": 0.0630947999369052,
      "grad_norm": 0.3637268543243408,
      "learning_rate": 0.00018741060159865378,
      "loss": 0.2811,
      "step": 2400
    },
    {
      "epoch": 0.06393606393606394,
      "grad_norm": 0.39438796043395996,
      "learning_rate": 0.00018724232225494322,
      "loss": 0.2722,
      "step": 2432
    },
    {
      "epoch": 0.06477732793522267,
      "grad_norm": 0.36667880415916443,
      "learning_rate": 0.00018707404291123264,
      "loss": 0.2789,
      "step": 2464
    },
    {
      "epoch": 0.06561859193438141,
      "grad_norm": 0.4246126413345337,
      "learning_rate": 0.0001869057635675221,
      "loss": 0.2751,
      "step": 2496
    },
    {
      "epoch": 0.06645985593354015,
      "grad_norm": 0.4419558644294739,
      "learning_rate": 0.00018673748422381154,
      "loss": 0.2827,
      "step": 2528
    },
    {
      "epoch": 0.06730111993269888,
      "grad_norm": 0.3600427508354187,
      "learning_rate": 0.00018656920488010096,
      "loss": 0.2715,
      "step": 2560
    },
    {
      "epoch": 0.06814238393185762,
      "grad_norm": 0.3500491976737976,
      "learning_rate": 0.00018640092553639043,
      "loss": 0.2814,
      "step": 2592
    },
    {
      "epoch": 0.06898364793101636,
      "grad_norm": 0.392668217420578,
      "learning_rate": 0.00018623264619267987,
      "loss": 0.2869,
      "step": 2624
    },
    {
      "epoch": 0.0698249119301751,
      "grad_norm": 0.37530988454818726,
      "learning_rate": 0.0001860643668489693,
      "loss": 0.2776,
      "step": 2656
    },
    {
      "epoch": 0.07066617592933383,
      "grad_norm": 0.35084259510040283,
      "learning_rate": 0.00018589608750525872,
      "loss": 0.2744,
      "step": 2688
    },
    {
      "epoch": 0.07150743992849257,
      "grad_norm": 0.4064619243144989,
      "learning_rate": 0.00018572780816154819,
      "loss": 0.2686,
      "step": 2720
    },
    {
      "epoch": 0.07234870392765129,
      "grad_norm": 0.3973282277584076,
      "learning_rate": 0.00018555952881783763,
      "loss": 0.2725,
      "step": 2752
    },
    {
      "epoch": 0.07318996792681003,
      "grad_norm": 0.3291339576244354,
      "learning_rate": 0.00018539124947412704,
      "loss": 0.274,
      "step": 2784
    },
    {
      "epoch": 0.07403123192596876,
      "grad_norm": 0.41167497634887695,
      "learning_rate": 0.0001852229701304165,
      "loss": 0.2709,
      "step": 2816
    },
    {
      "epoch": 0.0748724959251275,
      "grad_norm": 0.44621774554252625,
      "learning_rate": 0.00018505469078670595,
      "loss": 0.28,
      "step": 2848
    },
    {
      "epoch": 0.07571375992428624,
      "grad_norm": 0.4011802077293396,
      "learning_rate": 0.0001848864114429954,
      "loss": 0.278,
      "step": 2880
    },
    {
      "epoch": 0.07655502392344497,
      "grad_norm": 0.3639363646507263,
      "learning_rate": 0.0001847181320992848,
      "loss": 0.2756,
      "step": 2912
    },
    {
      "epoch": 0.07739628792260371,
      "grad_norm": 0.3593277335166931,
      "learning_rate": 0.00018454985275557427,
      "loss": 0.2794,
      "step": 2944
    },
    {
      "epoch": 0.07823755192176245,
      "grad_norm": 0.3897796869277954,
      "learning_rate": 0.0001843815734118637,
      "loss": 0.2771,
      "step": 2976
    },
    {
      "epoch": 0.07907881592092118,
      "grad_norm": 0.30488550662994385,
      "learning_rate": 0.00018421329406815315,
      "loss": 0.2812,
      "step": 3008
    },
    {
      "epoch": 0.07992007992007992,
      "grad_norm": 0.41372525691986084,
      "learning_rate": 0.0001840450147244426,
      "loss": 0.2678,
      "step": 3040
    },
    {
      "epoch": 0.08076134391923866,
      "grad_norm": 0.38331079483032227,
      "learning_rate": 0.00018387673538073203,
      "loss": 0.2789,
      "step": 3072
    },
    {
      "epoch": 0.0816026079183974,
      "grad_norm": 0.3839392066001892,
      "learning_rate": 0.00018370845603702147,
      "loss": 0.2779,
      "step": 3104
    },
    {
      "epoch": 0.08244387191755613,
      "grad_norm": 0.37332722544670105,
      "learning_rate": 0.00018354017669331088,
      "loss": 0.2848,
      "step": 3136
    },
    {
      "epoch": 0.08328513591671487,
      "grad_norm": 0.33761659264564514,
      "learning_rate": 0.00018337189734960035,
      "loss": 0.272,
      "step": 3168
    },
    {
      "epoch": 0.0841263999158736,
      "grad_norm": 0.3211279809474945,
      "learning_rate": 0.0001832036180058898,
      "loss": 0.2696,
      "step": 3200
    },
    {
      "epoch": 0.08496766391503234,
      "grad_norm": 0.3692023754119873,
      "learning_rate": 0.00018303533866217923,
      "loss": 0.277,
      "step": 3232
    },
    {
      "epoch": 0.08580892791419108,
      "grad_norm": 0.341141015291214,
      "learning_rate": 0.00018286705931846867,
      "loss": 0.2731,
      "step": 3264
    },
    {
      "epoch": 0.08665019191334981,
      "grad_norm": 0.34723100066185,
      "learning_rate": 0.0001826987799747581,
      "loss": 0.2756,
      "step": 3296
    },
    {
      "epoch": 0.08749145591250855,
      "grad_norm": 0.35167261958122253,
      "learning_rate": 0.00018253050063104755,
      "loss": 0.268,
      "step": 3328
    },
    {
      "epoch": 0.08833271991166727,
      "grad_norm": 0.419359028339386,
      "learning_rate": 0.000182362221287337,
      "loss": 0.2864,
      "step": 3360
    },
    {
      "epoch": 0.08917398391082601,
      "grad_norm": 0.3672769367694855,
      "learning_rate": 0.00018219394194362643,
      "loss": 0.2672,
      "step": 3392
    },
    {
      "epoch": 0.09001524790998475,
      "grad_norm": 0.44391903281211853,
      "learning_rate": 0.00018202566259991587,
      "loss": 0.2703,
      "step": 3424
    },
    {
      "epoch": 0.09085651190914348,
      "grad_norm": 0.3152555823326111,
      "learning_rate": 0.0001818573832562053,
      "loss": 0.275,
      "step": 3456
    },
    {
      "epoch": 0.09169777590830222,
      "grad_norm": 0.38706693053245544,
      "learning_rate": 0.00018168910391249475,
      "loss": 0.2768,
      "step": 3488
    },
    {
      "epoch": 0.09253903990746096,
      "grad_norm": 0.3607368469238281,
      "learning_rate": 0.0001815208245687842,
      "loss": 0.2745,
      "step": 3520
    },
    {
      "epoch": 0.0933803039066197,
      "grad_norm": 0.3978281319141388,
      "learning_rate": 0.00018135254522507363,
      "loss": 0.2725,
      "step": 3552
    },
    {
      "epoch": 0.09422156790577843,
      "grad_norm": 0.36797893047332764,
      "learning_rate": 0.00018118426588136307,
      "loss": 0.2786,
      "step": 3584
    },
    {
      "epoch": 0.09506283190493717,
      "grad_norm": 0.3707428574562073,
      "learning_rate": 0.00018101598653765251,
      "loss": 0.2715,
      "step": 3616
    },
    {
      "epoch": 0.0959040959040959,
      "grad_norm": 0.3527112305164337,
      "learning_rate": 0.00018084770719394195,
      "loss": 0.2763,
      "step": 3648
    },
    {
      "epoch": 0.09674535990325464,
      "grad_norm": 0.38577979803085327,
      "learning_rate": 0.0001806794278502314,
      "loss": 0.2676,
      "step": 3680
    },
    {
      "epoch": 0.09758662390241338,
      "grad_norm": 0.34795475006103516,
      "learning_rate": 0.00018051114850652084,
      "loss": 0.2708,
      "step": 3712
    },
    {
      "epoch": 0.09842788790157211,
      "grad_norm": 0.35432174801826477,
      "learning_rate": 0.00018034286916281028,
      "loss": 0.2673,
      "step": 3744
    },
    {
      "epoch": 0.09926915190073085,
      "grad_norm": 0.37588757276535034,
      "learning_rate": 0.00018017458981909972,
      "loss": 0.264,
      "step": 3776
    },
    {
      "epoch": 0.10011041589988959,
      "grad_norm": 0.31653717160224915,
      "learning_rate": 0.00018000631047538916,
      "loss": 0.272,
      "step": 3808
    },
    {
      "epoch": 0.10095167989904832,
      "grad_norm": 0.333118736743927,
      "learning_rate": 0.0001798380311316786,
      "loss": 0.2692,
      "step": 3840
    },
    {
      "epoch": 0.10179294389820706,
      "grad_norm": 0.3658456802368164,
      "learning_rate": 0.00017966975178796804,
      "loss": 0.2726,
      "step": 3872
    },
    {
      "epoch": 0.1026342078973658,
      "grad_norm": 0.33537691831588745,
      "learning_rate": 0.00017950147244425748,
      "loss": 0.2617,
      "step": 3904
    },
    {
      "epoch": 0.10347547189652453,
      "grad_norm": 0.29788440465927124,
      "learning_rate": 0.00017933319310054692,
      "loss": 0.2614,
      "step": 3936
    },
    {
      "epoch": 0.10431673589568326,
      "grad_norm": 0.39944151043891907,
      "learning_rate": 0.00017916491375683636,
      "loss": 0.2677,
      "step": 3968
    },
    {
      "epoch": 0.105157999894842,
      "grad_norm": 0.3498871624469757,
      "learning_rate": 0.0001789966344131258,
      "loss": 0.2637,
      "step": 4000
    },
    {
      "epoch": 0.10599926389400073,
      "grad_norm": 0.37968897819519043,
      "learning_rate": 0.00017882835506941524,
      "loss": 0.2665,
      "step": 4032
    },
    {
      "epoch": 0.10684052789315947,
      "grad_norm": 0.30595290660858154,
      "learning_rate": 0.00017866007572570468,
      "loss": 0.2657,
      "step": 4064
    },
    {
      "epoch": 0.1076817918923182,
      "grad_norm": 0.34290629625320435,
      "learning_rate": 0.00017849179638199412,
      "loss": 0.273,
      "step": 4096
    },
    {
      "epoch": 0.10852305589147694,
      "grad_norm": 0.47615334391593933,
      "learning_rate": 0.00017832351703828356,
      "loss": 0.2739,
      "step": 4128
    },
    {
      "epoch": 0.10936431989063568,
      "grad_norm": 0.33594924211502075,
      "learning_rate": 0.000178155237694573,
      "loss": 0.2686,
      "step": 4160
    },
    {
      "epoch": 0.11020558388979441,
      "grad_norm": 0.31274542212486267,
      "learning_rate": 0.00017798695835086244,
      "loss": 0.2646,
      "step": 4192
    },
    {
      "epoch": 0.11104684788895315,
      "grad_norm": 0.39757269620895386,
      "learning_rate": 0.00017781867900715188,
      "loss": 0.2789,
      "step": 4224
    },
    {
      "epoch": 0.11188811188811189,
      "grad_norm": 0.33215415477752686,
      "learning_rate": 0.00017765039966344132,
      "loss": 0.2792,
      "step": 4256
    },
    {
      "epoch": 0.11272937588727062,
      "grad_norm": 0.35941460728645325,
      "learning_rate": 0.00017748212031973076,
      "loss": 0.2714,
      "step": 4288
    },
    {
      "epoch": 0.11357063988642936,
      "grad_norm": 0.3715004622936249,
      "learning_rate": 0.0001773138409760202,
      "loss": 0.2673,
      "step": 4320
    },
    {
      "epoch": 0.1144119038855881,
      "grad_norm": 0.35454803705215454,
      "learning_rate": 0.00017714556163230964,
      "loss": 0.2658,
      "step": 4352
    },
    {
      "epoch": 0.11525316788474683,
      "grad_norm": 0.3620956540107727,
      "learning_rate": 0.00017697728228859908,
      "loss": 0.2569,
      "step": 4384
    },
    {
      "epoch": 0.11609443188390557,
      "grad_norm": 0.3584040403366089,
      "learning_rate": 0.00017680900294488852,
      "loss": 0.2733,
      "step": 4416
    },
    {
      "epoch": 0.11693569588306431,
      "grad_norm": 0.3674577474594116,
      "learning_rate": 0.00017664072360117796,
      "loss": 0.2763,
      "step": 4448
    },
    {
      "epoch": 0.11777695988222305,
      "grad_norm": 0.29409390687942505,
      "learning_rate": 0.0001764724442574674,
      "loss": 0.2705,
      "step": 4480
    },
    {
      "epoch": 0.11861822388138178,
      "grad_norm": 0.3977372348308563,
      "learning_rate": 0.00017630416491375684,
      "loss": 0.283,
      "step": 4512
    },
    {
      "epoch": 0.11945948788054052,
      "grad_norm": 0.42341503500938416,
      "learning_rate": 0.00017613588557004628,
      "loss": 0.2757,
      "step": 4544
    },
    {
      "epoch": 0.12030075187969924,
      "grad_norm": 0.33200231194496155,
      "learning_rate": 0.00017596760622633572,
      "loss": 0.2696,
      "step": 4576
    },
    {
      "epoch": 0.12114201587885798,
      "grad_norm": 0.3596971333026886,
      "learning_rate": 0.00017579932688262516,
      "loss": 0.2662,
      "step": 4608
    },
    {
      "epoch": 0.12198327987801671,
      "grad_norm": 0.38843071460723877,
      "learning_rate": 0.0001756310475389146,
      "loss": 0.276,
      "step": 4640
    },
    {
      "epoch": 0.12282454387717545,
      "grad_norm": 0.3357188105583191,
      "learning_rate": 0.00017546276819520404,
      "loss": 0.2609,
      "step": 4672
    },
    {
      "epoch": 0.12366580787633419,
      "grad_norm": 0.37999236583709717,
      "learning_rate": 0.00017529448885149348,
      "loss": 0.2722,
      "step": 4704
    },
    {
      "epoch": 0.12450707187549293,
      "grad_norm": 0.38939031958580017,
      "learning_rate": 0.00017512620950778292,
      "loss": 0.2715,
      "step": 4736
    },
    {
      "epoch": 0.12534833587465166,
      "grad_norm": 0.3880474269390106,
      "learning_rate": 0.00017495793016407237,
      "loss": 0.2795,
      "step": 4768
    },
    {
      "epoch": 0.1261895998738104,
      "grad_norm": 0.2945217490196228,
      "learning_rate": 0.0001747896508203618,
      "loss": 0.2611,
      "step": 4800
    },
    {
      "epoch": 0.12703086387296914,
      "grad_norm": 0.30474960803985596,
      "learning_rate": 0.00017462137147665125,
      "loss": 0.2669,
      "step": 4832
    },
    {
      "epoch": 0.12787212787212787,
      "grad_norm": 0.34069985151290894,
      "learning_rate": 0.00017445309213294069,
      "loss": 0.2656,
      "step": 4864
    },
    {
      "epoch": 0.1287133918712866,
      "grad_norm": 0.3172636926174164,
      "learning_rate": 0.00017428481278923013,
      "loss": 0.2734,
      "step": 4896
    },
    {
      "epoch": 0.12955465587044535,
      "grad_norm": 0.34449464082717896,
      "learning_rate": 0.00017411653344551957,
      "loss": 0.2623,
      "step": 4928
    },
    {
      "epoch": 0.13039591986960408,
      "grad_norm": 0.298846036195755,
      "learning_rate": 0.000173948254101809,
      "loss": 0.2661,
      "step": 4960
    },
    {
      "epoch": 0.13123718386876282,
      "grad_norm": 0.33594340085983276,
      "learning_rate": 0.00017377997475809847,
      "loss": 0.2668,
      "step": 4992
    },
    {
      "epoch": 0.13207844786792156,
      "grad_norm": 0.3175479769706726,
      "learning_rate": 0.0001736116954143879,
      "loss": 0.2651,
      "step": 5024
    },
    {
      "epoch": 0.1329197118670803,
      "grad_norm": 0.36334842443466187,
      "learning_rate": 0.00017344341607067733,
      "loss": 0.2735,
      "step": 5056
    },
    {
      "epoch": 0.13376097586623903,
      "grad_norm": 0.34937751293182373,
      "learning_rate": 0.00017327513672696677,
      "loss": 0.2729,
      "step": 5088
    },
    {
      "epoch": 0.13460223986539777,
      "grad_norm": 0.27712151408195496,
      "learning_rate": 0.0001731068573832562,
      "loss": 0.2639,
      "step": 5120
    },
    {
      "epoch": 0.1354435038645565,
      "grad_norm": 0.39334040880203247,
      "learning_rate": 0.00017293857803954565,
      "loss": 0.2675,
      "step": 5152
    },
    {
      "epoch": 0.13628476786371524,
      "grad_norm": 0.3171207010746002,
      "learning_rate": 0.0001727702986958351,
      "loss": 0.2666,
      "step": 5184
    },
    {
      "epoch": 0.13712603186287398,
      "grad_norm": 0.33499717712402344,
      "learning_rate": 0.00017260201935212456,
      "loss": 0.2718,
      "step": 5216
    },
    {
      "epoch": 0.1379672958620327,
      "grad_norm": 0.39390984177589417,
      "learning_rate": 0.00017243374000841397,
      "loss": 0.2662,
      "step": 5248
    },
    {
      "epoch": 0.13880855986119145,
      "grad_norm": 0.35512009263038635,
      "learning_rate": 0.0001722654606647034,
      "loss": 0.2703,
      "step": 5280
    },
    {
      "epoch": 0.1396498238603502,
      "grad_norm": 0.34620246291160583,
      "learning_rate": 0.00017209718132099285,
      "loss": 0.2693,
      "step": 5312
    },
    {
      "epoch": 0.14049108785950892,
      "grad_norm": 0.2913183271884918,
      "learning_rate": 0.0001719289019772823,
      "loss": 0.2584,
      "step": 5344
    },
    {
      "epoch": 0.14133235185866766,
      "grad_norm": 0.3730880618095398,
      "learning_rate": 0.00017176062263357173,
      "loss": 0.2698,
      "step": 5376
    },
    {
      "epoch": 0.1421736158578264,
      "grad_norm": 0.32229071855545044,
      "learning_rate": 0.00017159234328986117,
      "loss": 0.2713,
      "step": 5408
    },
    {
      "epoch": 0.14301487985698513,
      "grad_norm": 0.37457987666130066,
      "learning_rate": 0.00017142406394615064,
      "loss": 0.2756,
      "step": 5440
    },
    {
      "epoch": 0.14385614385614387,
      "grad_norm": 0.3475324213504791,
      "learning_rate": 0.00017125578460244005,
      "loss": 0.2723,
      "step": 5472
    },
    {
      "epoch": 0.14469740785530258,
      "grad_norm": 0.3198537826538086,
      "learning_rate": 0.0001710875052587295,
      "loss": 0.2531,
      "step": 5504
    },
    {
      "epoch": 0.14553867185446132,
      "grad_norm": 0.32878994941711426,
      "learning_rate": 0.00017091922591501893,
      "loss": 0.2678,
      "step": 5536
    },
    {
      "epoch": 0.14637993585362005,
      "grad_norm": 0.2868269383907318,
      "learning_rate": 0.0001707509465713084,
      "loss": 0.2764,
      "step": 5568
    },
    {
      "epoch": 0.1472211998527788,
      "grad_norm": 0.322247713804245,
      "learning_rate": 0.0001705826672275978,
      "loss": 0.2642,
      "step": 5600
    },
    {
      "epoch": 0.14806246385193753,
      "grad_norm": 0.31504026055336,
      "learning_rate": 0.00017041438788388725,
      "loss": 0.2722,
      "step": 5632
    },
    {
      "epoch": 0.14890372785109626,
      "grad_norm": 0.42000702023506165,
      "learning_rate": 0.00017024610854017672,
      "loss": 0.2766,
      "step": 5664
    },
    {
      "epoch": 0.149744991850255,
      "grad_norm": 0.265082985162735,
      "learning_rate": 0.00017007782919646613,
      "loss": 0.2663,
      "step": 5696
    },
    {
      "epoch": 0.15058625584941374,
      "grad_norm": 0.33354082703590393,
      "learning_rate": 0.00016990954985275557,
      "loss": 0.269,
      "step": 5728
    },
    {
      "epoch": 0.15142751984857247,
      "grad_norm": 0.29565703868865967,
      "learning_rate": 0.00016974127050904501,
      "loss": 0.2585,
      "step": 5760
    },
    {
      "epoch": 0.1522687838477312,
      "grad_norm": 0.3007037043571472,
      "learning_rate": 0.00016957299116533448,
      "loss": 0.2677,
      "step": 5792
    },
    {
      "epoch": 0.15311004784688995,
      "grad_norm": 0.3433666229248047,
      "learning_rate": 0.0001694047118216239,
      "loss": 0.2624,
      "step": 5824
    },
    {
      "epoch": 0.15395131184604868,
      "grad_norm": 0.2963417172431946,
      "learning_rate": 0.00016923643247791334,
      "loss": 0.2768,
      "step": 5856
    },
    {
      "epoch": 0.15479257584520742,
      "grad_norm": 0.292906790971756,
      "learning_rate": 0.0001690681531342028,
      "loss": 0.2631,
      "step": 5888
    },
    {
      "epoch": 0.15563383984436616,
      "grad_norm": 0.3588727116584778,
      "learning_rate": 0.00016889987379049224,
      "loss": 0.265,
      "step": 5920
    },
    {
      "epoch": 0.1564751038435249,
      "grad_norm": 0.35322490334510803,
      "learning_rate": 0.00016873159444678166,
      "loss": 0.2578,
      "step": 5952
    },
    {
      "epoch": 0.15731636784268363,
      "grad_norm": 0.3415665924549103,
      "learning_rate": 0.0001685633151030711,
      "loss": 0.2619,
      "step": 5984
    },
    {
      "epoch": 0.15815763184184237,
      "grad_norm": 0.3826902210712433,
      "learning_rate": 0.00016839503575936056,
      "loss": 0.2721,
      "step": 6016
    },
    {
      "epoch": 0.1589988958410011,
      "grad_norm": 0.3931109309196472,
      "learning_rate": 0.00016822675641564998,
      "loss": 0.2744,
      "step": 6048
    },
    {
      "epoch": 0.15984015984015984,
      "grad_norm": 0.39778104424476624,
      "learning_rate": 0.00016805847707193942,
      "loss": 0.2568,
      "step": 6080
    },
    {
      "epoch": 0.16068142383931858,
      "grad_norm": 0.37442344427108765,
      "learning_rate": 0.00016789019772822886,
      "loss": 0.2645,
      "step": 6112
    },
    {
      "epoch": 0.1615226878384773,
      "grad_norm": 0.32828569412231445,
      "learning_rate": 0.00016772191838451832,
      "loss": 0.2585,
      "step": 6144
    },
    {
      "epoch": 0.16236395183763605,
      "grad_norm": 0.3448491096496582,
      "learning_rate": 0.00016755363904080774,
      "loss": 0.2728,
      "step": 6176
    },
    {
      "epoch": 0.1632052158367948,
      "grad_norm": 0.34187051653862,
      "learning_rate": 0.00016738535969709718,
      "loss": 0.2684,
      "step": 6208
    },
    {
      "epoch": 0.16404647983595352,
      "grad_norm": 0.3424242436885834,
      "learning_rate": 0.00016721708035338665,
      "loss": 0.271,
      "step": 6240
    },
    {
      "epoch": 0.16488774383511226,
      "grad_norm": 0.3555494248867035,
      "learning_rate": 0.00016704880100967606,
      "loss": 0.2665,
      "step": 6272
    },
    {
      "epoch": 0.165729007834271,
      "grad_norm": 0.3421440124511719,
      "learning_rate": 0.0001668805216659655,
      "loss": 0.2688,
      "step": 6304
    },
    {
      "epoch": 0.16657027183342973,
      "grad_norm": 0.3647392690181732,
      "learning_rate": 0.00016671224232225494,
      "loss": 0.2599,
      "step": 6336
    },
    {
      "epoch": 0.16741153583258847,
      "grad_norm": 0.3901768624782562,
      "learning_rate": 0.0001665439629785444,
      "loss": 0.2592,
      "step": 6368
    },
    {
      "epoch": 0.1682527998317472,
      "grad_norm": 0.3470938205718994,
      "learning_rate": 0.00016637568363483382,
      "loss": 0.2689,
      "step": 6400
    },
    {
      "epoch": 0.16909406383090594,
      "grad_norm": 0.3250635266304016,
      "learning_rate": 0.00016620740429112326,
      "loss": 0.2666,
      "step": 6432
    },
    {
      "epoch": 0.16993532783006468,
      "grad_norm": 0.34194937348365784,
      "learning_rate": 0.00016603912494741273,
      "loss": 0.2687,
      "step": 6464
    },
    {
      "epoch": 0.17077659182922342,
      "grad_norm": 0.35884949564933777,
      "learning_rate": 0.00016587084560370217,
      "loss": 0.2595,
      "step": 6496
    },
    {
      "epoch": 0.17161785582838215,
      "grad_norm": 0.3526507318019867,
      "learning_rate": 0.00016570256625999158,
      "loss": 0.2542,
      "step": 6528
    },
    {
      "epoch": 0.1724591198275409,
      "grad_norm": 0.3068040609359741,
      "learning_rate": 0.00016553428691628102,
      "loss": 0.2641,
      "step": 6560
    },
    {
      "epoch": 0.17330038382669963,
      "grad_norm": 0.5460326671600342,
      "learning_rate": 0.0001653660075725705,
      "loss": 0.2634,
      "step": 6592
    },
    {
      "epoch": 0.17414164782585836,
      "grad_norm": 0.4046333134174347,
      "learning_rate": 0.0001651977282288599,
      "loss": 0.2728,
      "step": 6624
    },
    {
      "epoch": 0.1749829118250171,
      "grad_norm": 0.31564852595329285,
      "learning_rate": 0.00016502944888514934,
      "loss": 0.2625,
      "step": 6656
    },
    {
      "epoch": 0.17582417582417584,
      "grad_norm": 0.3451630175113678,
      "learning_rate": 0.0001648611695414388,
      "loss": 0.2581,
      "step": 6688
    },
    {
      "epoch": 0.17666543982333455,
      "grad_norm": 0.39108043909072876,
      "learning_rate": 0.00016469289019772825,
      "loss": 0.264,
      "step": 6720
    },
    {
      "epoch": 0.17750670382249328,
      "grad_norm": 0.3158724009990692,
      "learning_rate": 0.00016452461085401766,
      "loss": 0.2643,
      "step": 6752
    },
    {
      "epoch": 0.17834796782165202,
      "grad_norm": 0.3529897928237915,
      "learning_rate": 0.0001643563315103071,
      "loss": 0.2691,
      "step": 6784
    },
    {
      "epoch": 0.17918923182081076,
      "grad_norm": 0.27523696422576904,
      "learning_rate": 0.00016418805216659657,
      "loss": 0.2651,
      "step": 6816
    },
    {
      "epoch": 0.1800304958199695,
      "grad_norm": 0.35384413599967957,
      "learning_rate": 0.000164019772822886,
      "loss": 0.273,
      "step": 6848
    },
    {
      "epoch": 0.18087175981912823,
      "grad_norm": 0.35980916023254395,
      "learning_rate": 0.00016385149347917542,
      "loss": 0.2546,
      "step": 6880
    },
    {
      "epoch": 0.18171302381828697,
      "grad_norm": 0.37403127551078796,
      "learning_rate": 0.0001636832141354649,
      "loss": 0.2674,
      "step": 6912
    },
    {
      "epoch": 0.1825542878174457,
      "grad_norm": 0.3273882269859314,
      "learning_rate": 0.00016351493479175433,
      "loss": 0.2627,
      "step": 6944
    },
    {
      "epoch": 0.18339555181660444,
      "grad_norm": 0.3049343228340149,
      "learning_rate": 0.00016334665544804375,
      "loss": 0.2613,
      "step": 6976
    },
    {
      "epoch": 0.18423681581576318,
      "grad_norm": 0.2930116355419159,
      "learning_rate": 0.00016317837610433319,
      "loss": 0.2649,
      "step": 7008
    },
    {
      "epoch": 0.18507807981492191,
      "grad_norm": 0.2955911159515381,
      "learning_rate": 0.00016301009676062265,
      "loss": 0.2581,
      "step": 7040
    },
    {
      "epoch": 0.18591934381408065,
      "grad_norm": 0.39869174361228943,
      "learning_rate": 0.0001628418174169121,
      "loss": 0.2637,
      "step": 7072
    },
    {
      "epoch": 0.1867606078132394,
      "grad_norm": 0.34323081374168396,
      "learning_rate": 0.0001626735380732015,
      "loss": 0.2632,
      "step": 7104
    },
    {
      "epoch": 0.18760187181239812,
      "grad_norm": 0.3395211100578308,
      "learning_rate": 0.00016250525872949097,
      "loss": 0.2561,
      "step": 7136
    },
    {
      "epoch": 0.18844313581155686,
      "grad_norm": 0.3675766587257385,
      "learning_rate": 0.00016233697938578041,
      "loss": 0.2667,
      "step": 7168
    },
    {
      "epoch": 0.1892843998107156,
      "grad_norm": 0.3576664626598358,
      "learning_rate": 0.00016216870004206985,
      "loss": 0.2628,
      "step": 7200
    },
    {
      "epoch": 0.19012566380987433,
      "grad_norm": 0.45651012659072876,
      "learning_rate": 0.00016200042069835927,
      "loss": 0.267,
      "step": 7232
    },
    {
      "epoch": 0.19096692780903307,
      "grad_norm": 0.3562227785587311,
      "learning_rate": 0.00016183214135464873,
      "loss": 0.2604,
      "step": 7264
    },
    {
      "epoch": 0.1918081918081918,
      "grad_norm": 0.3420262634754181,
      "learning_rate": 0.00016166386201093818,
      "loss": 0.261,
      "step": 7296
    },
    {
      "epoch": 0.19264945580735054,
      "grad_norm": 0.3228318393230438,
      "learning_rate": 0.0001614955826672276,
      "loss": 0.2555,
      "step": 7328
    },
    {
      "epoch": 0.19349071980650928,
      "grad_norm": 0.3455546498298645,
      "learning_rate": 0.00016132730332351706,
      "loss": 0.2558,
      "step": 7360
    },
    {
      "epoch": 0.19433198380566802,
      "grad_norm": 0.32144686579704285,
      "learning_rate": 0.0001611590239798065,
      "loss": 0.2586,
      "step": 7392
    },
    {
      "epoch": 0.19517324780482675,
      "grad_norm": 0.3306371867656708,
      "learning_rate": 0.00016099074463609594,
      "loss": 0.2456,
      "step": 7424
    },
    {
      "epoch": 0.1960145118039855,
      "grad_norm": 0.34964650869369507,
      "learning_rate": 0.00016082246529238535,
      "loss": 0.2628,
      "step": 7456
    },
    {
      "epoch": 0.19685577580314423,
      "grad_norm": 0.3152282238006592,
      "learning_rate": 0.00016065418594867482,
      "loss": 0.2606,
      "step": 7488
    },
    {
      "epoch": 0.19769703980230297,
      "grad_norm": 0.33188706636428833,
      "learning_rate": 0.00016048590660496426,
      "loss": 0.2561,
      "step": 7520
    },
    {
      "epoch": 0.1985383038014617,
      "grad_norm": 0.3314560651779175,
      "learning_rate": 0.00016031762726125367,
      "loss": 0.2574,
      "step": 7552
    },
    {
      "epoch": 0.19937956780062044,
      "grad_norm": 0.3271082937717438,
      "learning_rate": 0.00016014934791754314,
      "loss": 0.2684,
      "step": 7584
    },
    {
      "epoch": 0.20022083179977918,
      "grad_norm": 0.33413076400756836,
      "learning_rate": 0.00015998106857383258,
      "loss": 0.2618,
      "step": 7616
    },
    {
      "epoch": 0.2010620957989379,
      "grad_norm": 0.3320523202419281,
      "learning_rate": 0.00015981278923012202,
      "loss": 0.2673,
      "step": 7648
    },
    {
      "epoch": 0.20190335979809665,
      "grad_norm": 0.3264504373073578,
      "learning_rate": 0.00015964450988641143,
      "loss": 0.2612,
      "step": 7680
    },
    {
      "epoch": 0.20274462379725539,
      "grad_norm": 0.26136064529418945,
      "learning_rate": 0.0001594762305427009,
      "loss": 0.2515,
      "step": 7712
    },
    {
      "epoch": 0.20358588779641412,
      "grad_norm": 0.3035871386528015,
      "learning_rate": 0.00015930795119899034,
      "loss": 0.2662,
      "step": 7744
    },
    {
      "epoch": 0.20442715179557286,
      "grad_norm": 0.33952006697654724,
      "learning_rate": 0.00015913967185527978,
      "loss": 0.2561,
      "step": 7776
    },
    {
      "epoch": 0.2052684157947316,
      "grad_norm": 0.3256785273551941,
      "learning_rate": 0.0001589713925115692,
      "loss": 0.265,
      "step": 7808
    },
    {
      "epoch": 0.20610967979389033,
      "grad_norm": 0.3032751679420471,
      "learning_rate": 0.00015880311316785866,
      "loss": 0.2582,
      "step": 7840
    },
    {
      "epoch": 0.20695094379304907,
      "grad_norm": 0.3466610014438629,
      "learning_rate": 0.0001586348338241481,
      "loss": 0.2639,
      "step": 7872
    },
    {
      "epoch": 0.2077922077922078,
      "grad_norm": 0.26841822266578674,
      "learning_rate": 0.00015846655448043751,
      "loss": 0.2696,
      "step": 7904
    },
    {
      "epoch": 0.20863347179136651,
      "grad_norm": 0.3209629952907562,
      "learning_rate": 0.00015829827513672698,
      "loss": 0.2573,
      "step": 7936
    },
    {
      "epoch": 0.20947473579052525,
      "grad_norm": 0.3291485905647278,
      "learning_rate": 0.00015812999579301642,
      "loss": 0.2555,
      "step": 7968
    },
    {
      "epoch": 0.210315999789684,
      "grad_norm": 0.34550851583480835,
      "learning_rate": 0.00015796171644930586,
      "loss": 0.2609,
      "step": 8000
    },
    {
      "epoch": 0.21115726378884273,
      "grad_norm": 0.2751707434654236,
      "learning_rate": 0.00015779343710559527,
      "loss": 0.2532,
      "step": 8032
    },
    {
      "epoch": 0.21199852778800146,
      "grad_norm": 0.24315132200717926,
      "learning_rate": 0.00015762515776188474,
      "loss": 0.2618,
      "step": 8064
    },
    {
      "epoch": 0.2128397917871602,
      "grad_norm": 0.37756800651550293,
      "learning_rate": 0.00015745687841817418,
      "loss": 0.2589,
      "step": 8096
    },
    {
      "epoch": 0.21368105578631894,
      "grad_norm": 0.3040754199028015,
      "learning_rate": 0.00015728859907446362,
      "loss": 0.2625,
      "step": 8128
    },
    {
      "epoch": 0.21452231978547767,
      "grad_norm": 0.34333881735801697,
      "learning_rate": 0.00015712031973075306,
      "loss": 0.2548,
      "step": 8160
    },
    {
      "epoch": 0.2153635837846364,
      "grad_norm": 0.33961108326911926,
      "learning_rate": 0.0001569520403870425,
      "loss": 0.265,
      "step": 8192
    },
    {
      "epoch": 0.21620484778379515,
      "grad_norm": 0.3193552792072296,
      "learning_rate": 0.00015678376104333194,
      "loss": 0.2643,
      "step": 8224
    },
    {
      "epoch": 0.21704611178295388,
      "grad_norm": 0.33901169896125793,
      "learning_rate": 0.00015661548169962136,
      "loss": 0.2555,
      "step": 8256
    },
    {
      "epoch": 0.21788737578211262,
      "grad_norm": 0.3331260681152344,
      "learning_rate": 0.00015644720235591082,
      "loss": 0.2631,
      "step": 8288
    },
    {
      "epoch": 0.21872863978127136,
      "grad_norm": 0.27894917130470276,
      "learning_rate": 0.00015627892301220026,
      "loss": 0.26,
      "step": 8320
    },
    {
      "epoch": 0.2195699037804301,
      "grad_norm": 0.43506884574890137,
      "learning_rate": 0.0001561106436684897,
      "loss": 0.2644,
      "step": 8352
    },
    {
      "epoch": 0.22041116777958883,
      "grad_norm": 0.35943150520324707,
      "learning_rate": 0.00015594236432477915,
      "loss": 0.2737,
      "step": 8384
    },
    {
      "epoch": 0.22125243177874757,
      "grad_norm": 0.36769041419029236,
      "learning_rate": 0.00015577408498106859,
      "loss": 0.2518,
      "step": 8416
    },
    {
      "epoch": 0.2220936957779063,
      "grad_norm": 0.32038643956184387,
      "learning_rate": 0.00015560580563735803,
      "loss": 0.262,
      "step": 8448
    },
    {
      "epoch": 0.22293495977706504,
      "grad_norm": 0.3165859878063202,
      "learning_rate": 0.00015543752629364747,
      "loss": 0.2509,
      "step": 8480
    },
    {
      "epoch": 0.22377622377622378,
      "grad_norm": 0.35394009947776794,
      "learning_rate": 0.0001552692469499369,
      "loss": 0.2611,
      "step": 8512
    },
    {
      "epoch": 0.2246174877753825,
      "grad_norm": 0.35313665866851807,
      "learning_rate": 0.00015510096760622635,
      "loss": 0.2553,
      "step": 8544
    },
    {
      "epoch": 0.22545875177454125,
      "grad_norm": 0.37367722392082214,
      "learning_rate": 0.0001549326882625158,
      "loss": 0.2705,
      "step": 8576
    },
    {
      "epoch": 0.2263000157737,
      "grad_norm": 0.2962832450866699,
      "learning_rate": 0.00015476440891880523,
      "loss": 0.2583,
      "step": 8608
    },
    {
      "epoch": 0.22714127977285872,
      "grad_norm": 0.3838392496109009,
      "learning_rate": 0.00015459612957509467,
      "loss": 0.2604,
      "step": 8640
    },
    {
      "epoch": 0.22798254377201746,
      "grad_norm": 0.28124845027923584,
      "learning_rate": 0.0001544278502313841,
      "loss": 0.2587,
      "step": 8672
    },
    {
      "epoch": 0.2288238077711762,
      "grad_norm": 0.4155752658843994,
      "learning_rate": 0.00015425957088767355,
      "loss": 0.2558,
      "step": 8704
    },
    {
      "epoch": 0.22966507177033493,
      "grad_norm": 0.3204725980758667,
      "learning_rate": 0.000154091291543963,
      "loss": 0.2672,
      "step": 8736
    },
    {
      "epoch": 0.23050633576949367,
      "grad_norm": 0.3795086741447449,
      "learning_rate": 0.00015392301220025243,
      "loss": 0.2606,
      "step": 8768
    },
    {
      "epoch": 0.2313475997686524,
      "grad_norm": 0.29627349972724915,
      "learning_rate": 0.00015375473285654187,
      "loss": 0.2591,
      "step": 8800
    },
    {
      "epoch": 0.23218886376781114,
      "grad_norm": 0.3479756712913513,
      "learning_rate": 0.0001535864535128313,
      "loss": 0.2545,
      "step": 8832
    },
    {
      "epoch": 0.23303012776696988,
      "grad_norm": 0.36412668228149414,
      "learning_rate": 0.00015341817416912075,
      "loss": 0.2647,
      "step": 8864
    },
    {
      "epoch": 0.23387139176612862,
      "grad_norm": 0.33262506127357483,
      "learning_rate": 0.0001532498948254102,
      "loss": 0.2632,
      "step": 8896
    },
    {
      "epoch": 0.23471265576528735,
      "grad_norm": 0.3414536416530609,
      "learning_rate": 0.00015308161548169963,
      "loss": 0.2602,
      "step": 8928
    },
    {
      "epoch": 0.2355539197644461,
      "grad_norm": 0.3930247724056244,
      "learning_rate": 0.00015291333613798907,
      "loss": 0.2535,
      "step": 8960
    },
    {
      "epoch": 0.23639518376360483,
      "grad_norm": 0.3586319088935852,
      "learning_rate": 0.0001527450567942785,
      "loss": 0.2595,
      "step": 8992
    },
    {
      "epoch": 0.23723644776276356,
      "grad_norm": 0.34378135204315186,
      "learning_rate": 0.00015257677745056795,
      "loss": 0.2636,
      "step": 9024
    },
    {
      "epoch": 0.2380777117619223,
      "grad_norm": 0.3463638126850128,
      "learning_rate": 0.0001524084981068574,
      "loss": 0.2646,
      "step": 9056
    },
    {
      "epoch": 0.23891897576108104,
      "grad_norm": 0.363606721162796,
      "learning_rate": 0.00015224021876314683,
      "loss": 0.2573,
      "step": 9088
    },
    {
      "epoch": 0.23976023976023977,
      "grad_norm": 0.32031679153442383,
      "learning_rate": 0.00015207193941943627,
      "loss": 0.2716,
      "step": 9120
    },
    {
      "epoch": 0.24060150375939848,
      "grad_norm": 0.3409512937068939,
      "learning_rate": 0.0001519036600757257,
      "loss": 0.2641,
      "step": 9152
    },
    {
      "epoch": 0.24144276775855722,
      "grad_norm": 0.30720746517181396,
      "learning_rate": 0.00015173538073201515,
      "loss": 0.2648,
      "step": 9184
    },
    {
      "epoch": 0.24228403175771596,
      "grad_norm": 0.3366183936595917,
      "learning_rate": 0.0001515671013883046,
      "loss": 0.2584,
      "step": 9216
    },
    {
      "epoch": 0.2431252957568747,
      "grad_norm": 0.3001071512699127,
      "learning_rate": 0.00015139882204459403,
      "loss": 0.2581,
      "step": 9248
    },
    {
      "epoch": 0.24396655975603343,
      "grad_norm": 0.2818130850791931,
      "learning_rate": 0.00015123054270088347,
      "loss": 0.2608,
      "step": 9280
    },
    {
      "epoch": 0.24480782375519217,
      "grad_norm": 0.3451496958732605,
      "learning_rate": 0.00015106226335717291,
      "loss": 0.2687,
      "step": 9312
    },
    {
      "epoch": 0.2456490877543509,
      "grad_norm": 0.3293221592903137,
      "learning_rate": 0.00015089398401346235,
      "loss": 0.2496,
      "step": 9344
    },
    {
      "epoch": 0.24649035175350964,
      "grad_norm": 0.31917816400527954,
      "learning_rate": 0.0001507257046697518,
      "loss": 0.262,
      "step": 9376
    },
    {
      "epoch": 0.24733161575266838,
      "grad_norm": 0.35834479331970215,
      "learning_rate": 0.00015055742532604123,
      "loss": 0.2567,
      "step": 9408
    },
    {
      "epoch": 0.2481728797518271,
      "grad_norm": 0.2899259328842163,
      "learning_rate": 0.00015038914598233067,
      "loss": 0.2609,
      "step": 9440
    },
    {
      "epoch": 0.24901414375098585,
      "grad_norm": 0.3348793089389801,
      "learning_rate": 0.00015022086663862012,
      "loss": 0.2571,
      "step": 9472
    },
    {
      "epoch": 0.2498554077501446,
      "grad_norm": 0.30929070711135864,
      "learning_rate": 0.00015005258729490956,
      "loss": 0.2568,
      "step": 9504
    },
    {
      "epoch": 0.2506966717493033,
      "grad_norm": 0.28561702370643616,
      "learning_rate": 0.000149884307951199,
      "loss": 0.254,
      "step": 9536
    },
    {
      "epoch": 0.25153793574846206,
      "grad_norm": 0.3009265661239624,
      "learning_rate": 0.00014971602860748844,
      "loss": 0.2543,
      "step": 9568
    },
    {
      "epoch": 0.2523791997476208,
      "grad_norm": 0.38973015546798706,
      "learning_rate": 0.00014954774926377788,
      "loss": 0.2628,
      "step": 9600
    },
    {
      "epoch": 0.25322046374677953,
      "grad_norm": 0.3601813316345215,
      "learning_rate": 0.00014937946992006732,
      "loss": 0.2671,
      "step": 9632
    },
    {
      "epoch": 0.25406172774593827,
      "grad_norm": 0.3117876648902893,
      "learning_rate": 0.00014921119057635676,
      "loss": 0.2623,
      "step": 9664
    },
    {
      "epoch": 0.254902991745097,
      "grad_norm": 0.30650630593299866,
      "learning_rate": 0.0001490429112326462,
      "loss": 0.2566,
      "step": 9696
    },
    {
      "epoch": 0.25574425574425574,
      "grad_norm": 0.3350464999675751,
      "learning_rate": 0.00014887463188893564,
      "loss": 0.2645,
      "step": 9728
    },
    {
      "epoch": 0.2565855197434145,
      "grad_norm": 0.34985119104385376,
      "learning_rate": 0.0001487063525452251,
      "loss": 0.2697,
      "step": 9760
    },
    {
      "epoch": 0.2574267837425732,
      "grad_norm": 0.3413527309894562,
      "learning_rate": 0.00014853807320151452,
      "loss": 0.2592,
      "step": 9792
    }
  ],
  "logging_steps": 32,
  "max_steps": 38037,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 32,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1183652090150912e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
