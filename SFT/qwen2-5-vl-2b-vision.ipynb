{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11800121,"sourceType":"datasetVersion","datasetId":7410323},{"sourceId":119203882,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\nimport os\nif \"COLAB_\" not in \"\".join(os.environ.keys()):\n    !pip install unsloth\nelse:\n    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n    !pip install --no-deps unsloth","metadata":{"id":"8mnDnAg2NUoF","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:55:05.147089Z","iopub.execute_input":"2025-05-13T18:55:05.147259Z","iopub.status.idle":"2025-05-13T18:55:18.713848Z","shell.execute_reply.started":"2025-05-13T18:55:05.147243Z","shell.execute_reply":"2025-05-13T18:55:18.712936Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!wget https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\n!tar -xf abo-images-small.tar","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCm6SwajQNMy","outputId":"89c17a2c-5fbb-4848-9e2f-947282dbff18","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"z9_0IL7LQcRM","outputId":"585a4e5b-66b9-45aa-909f-a2d4500ce79c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n# ========= CONFIG =========\nlisting = \"0\"\ncsv_path = \"/kaggle/input/abo-dataset-merged/merged_listings.csv\"  # CSV must contain: image_path, question, one_word_answer\n#get length of csv filevvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv\nf = open(csv_path, \"r\")\nlines = f.readlines()\nf.close()\n\n\nmodel_dir = \"/kaggle/working/models\"\noutput_dir = \"/kaggle/working/lora_on_listing\"\nimages_root = \"/kaggle/input/abo-dataset\"\nbatch_size = 4\nlenght_of_dataset = len(lines) -1\nmax_steps = (len(lines)-1)//batch_size\nprint(f\"Steps per epoch: {max_steps}\")\ncheckpoint_path = None\n# ===========================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndel lines","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVcieD3SQd_e","outputId":"f9899c87-1673-4141-f96f-b00b4f764217","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:55:18.714826Z","iopub.execute_input":"2025-05-13T18:55:18.715048Z","iopub.status.idle":"2025-05-13T18:55:24.550537Z","shell.execute_reply.started":"2025-05-13T18:55:18.715025Z","shell.execute_reply":"2025-05-13T18:55:24.549894Z"}},"outputs":[{"name":"stdout","text":"Steps per epoch: 304298\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Unsloth","metadata":{"id":"9xLDGk41C7IF"}},{"cell_type":"code","source":"from unsloth import FastVisionModel # FastLanguageModel for LLMs\nimport torch\nfrom transformers import AutoProcessor\n\n\n\n\nmodel, tokenizer = FastVisionModel.from_pretrained(\n    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",\n    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmUBVEnvCDJv","outputId":"c4e79bcf-82a5-46ab-9a27-6f54d0ef7705","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:11:09.489956Z","iopub.execute_input":"2025-05-13T19:11:09.490233Z","iopub.status.idle":"2025-05-13T19:11:21.857754Z","shell.execute_reply.started":"2025-05-13T19:11:09.490213Z","shell.execute_reply":"2025-05-13T19:11:21.857104Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.5.2: Fast Qwen2_Vl patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"model = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers     = True, # False if not finetuning vision layers\n    finetune_language_layers   = True, # False if not finetuning language layers\n    finetune_attention_modules = True, # False if not finetuning attention layers\n    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n\n    r = 4,           # The larger, the higher the accuracy, but might overfit\n    lora_alpha = 4,  # Recommended alpha == r at least\n    lora_dropout = 0,\n    bias = \"none\",\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n)","metadata":{"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/","height":402},"outputId":"6df28474-ae53-4d3d-d06d-b5f11b3abc24","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:11:21.858807Z","iopub.execute_input":"2025-05-13T19:11:21.859018Z","iopub.status.idle":"2025-05-13T19:11:27.827802Z","shell.execute_reply.started":"2025-05-13T19:11:21.859001Z","shell.execute_reply":"2025-05-13T19:11:27.827223Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Making `model.base_model.model.visual` require gradients\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from torch.utils.data import IterableDataset, DataLoader\nfrom PIL import Image\nclass VQALazyIterableDataset(IterableDataset):\n    def __init__(self, dataset_stream, lenght_of_dataset,tokenizer):\n        self.dataset_stream = dataset_stream\n        self.lenght_of_dataset = lenght_of_dataset\n        self.images_root = \"/kaggle/input/abo-dataset/abo_small/small\"\n        self.tokenizer = tokenizer\n\n    def preprocess(self, example):\n\n\n        image = Image.open(f\"{self.images_root}/{example['image_path']}\").convert(\"RGB\")\n        image = image.resize((224, 224))\n        question = example[\"question\"]\n        answer = example[\"answer\"]\n        if not answer \n\n        messages = [\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"image\"},\n                {\"type\": \"text\", \"text\": question}\n            ]}\n        ]\n        input_text = self.tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n        inputs = self.tokenizer(\n            image,\n            input_text,\n            add_special_tokens = False,\n            max_length=300,\n            truncation=True,\n            return_tensors = \"pt\",\n            padding=\"max_length\"\n        )\n\n        labels = self.tokenizer.tokenizer(\n                text=answer,\n                add_special_tokens = False,\n                max_length=300,\n                truncation=True,\n                padding=\"max_length\",\n                return_tensors = \"pt\",\n            ).input_ids\n\n\n\n        return {\n            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n            \"labels\": labels.squeeze(0),\n            \"image_grid_thw\": inputs[\"image_grid_thw\"].squeeze(0)\n            }\n\n\n\n    def __iter__(self):\n        for example in self.dataset_stream:\n            processed = self.preprocess(example)\n            if processed:\n                yield processed\n    def __len__(self):\n      return self.lenght_of_dataset\n\n","metadata":{"id":"2V6E4SZwQy-Y","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:11:27.828542Z","iopub.execute_input":"2025-05-13T19:11:27.828728Z","iopub.status.idle":"2025-05-13T19:11:27.837029Z","shell.execute_reply.started":"2025-05-13T19:11:27.828714Z","shell.execute_reply":"2025-05-13T19:11:27.836277Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def collate_fn(batch):\n    import torch\n\n    # Extract fields from batch\n    pixel_values = [example[\"pixel_values\"] for example in batch]\n    input_ids = [example[\"input_ids\"] for example in batch]\n    attention_mask = [example[\"attention_mask\"] for example in batch]\n    labels = [example[\"labels\"] for example in batch]\n    image_grid_thw = [example[\"image_grid_thw\"] for example in batch]\n\n    # Stack vision-related tensors\n    pixel_values = torch.stack(pixel_values)         # [B, 256, 1176]\n    image_grid_thw = torch.stack(image_grid_thw)     # [B, 3]\n\n    # Tokenizer padding for input_ids & attention_mask\n    text_inputs = [\n        {\"input_ids\": ids, \"attention_mask\": mask}\n        for ids, mask in zip(input_ids, attention_mask)\n    ]\n    padded_inputs = tokenizer.tokenizer.pad(\n        text_inputs,\n        return_tensors=\"pt\"\n    )\n\n    # Tokenizer padding for labels\n    padded_labels = tokenizer.tokenizer.pad(\n        [{\"input_ids\": lbl} for lbl in labels],\n        return_tensors=\"pt\"\n    )[\"input_ids\"]\n\n    # Replace padding token id with -100 for loss masking\n    padded_labels[padded_labels == tokenizer.tokenizer.pad_token_id] = -100\n\n    return {\n        \"pixel_values\": pixel_values,                           # [B, 256, 1176]\n        \"input_ids\": padded_inputs[\"input_ids\"],                # [B, T]\n        \"attention_mask\": padded_inputs[\"attention_mask\"],      # [B, T]\n        \"labels\": padded_labels,                                # [B, T] with -100\n        \"image_grid_thw\": image_grid_thw                        # [B, 3]\n    }\n","metadata":{"id":"C9Rvo3FfiZO2","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:11:27.838350Z","iopub.execute_input":"2025-05-13T19:11:27.838587Z","iopub.status.idle":"2025-05-13T19:11:27.857464Z","shell.execute_reply.started":"2025-05-13T19:11:27.838572Z","shell.execute_reply":"2025-05-13T19:11:27.856861Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"csv\", data_files=csv_path, split=\"train\", streaming=True)\ndataset = dataset.filter(lambda x: x['image_path'] and x[\"question\"] and x[\"answer\"])","metadata":{"id":"LjY75GoYUCB8","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:21:12.634537Z","iopub.execute_input":"2025-05-13T19:21:12.634818Z","iopub.status.idle":"2025-05-13T19:21:12.857321Z","shell.execute_reply.started":"2025-05-13T19:21:12.634797Z","shell.execute_reply":"2025-05-13T19:21:12.856822Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"Let's take an overview look at the dataset. We shall see what the 3rd image is, and what caption it had.","metadata":{"id":"W1W2Qhsz6rUT"}},{"cell_type":"code","source":"","metadata":{"id":"7LIksTxGsABV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vqa_dataset = VQALazyIterableDataset(dataset,lenght_of_dataset, tokenizer)\n","metadata":{"id":"bfcSGwIb6p_R","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:21:21.493131Z","iopub.execute_input":"2025-05-13T19:21:21.493836Z","iopub.status.idle":"2025-05-13T19:21:21.497278Z","shell.execute_reply.started":"2025-05-13T19:21:21.493811Z","shell.execute_reply":"2025-05-13T19:21:21.496540Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"dataloader = DataLoader(\n    vqa_dataset,\n    batch_size=1,\n)\nbatch = next(iter(dataloader))\nfor k, v in batch.items():\n    print(k, v.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amkWVOXBtIwH","outputId":"9bb5b230-9e39-4702-ed18-57f2657f339f","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:21:25.326120Z","iopub.execute_input":"2025-05-13T19:21:25.326382Z","iopub.status.idle":"2025-05-13T19:21:25.360344Z","shell.execute_reply.started":"2025-05-13T19:21:25.326363Z","shell.execute_reply":"2025-05-13T19:21:25.359728Z"}},"outputs":[{"name":"stdout","text":"pixel_values torch.Size([1, 256, 1176])\ninput_ids torch.Size([1, 300])\nattention_mask torch.Size([1, 300])\nlabels torch.Size([1, 300])\nimage_grid_thw torch.Size([1, 3])\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from unsloth import is_bf16_supported\nfrom unsloth.trainer import UnslothVisionDataCollator\nfrom trl import SFTTrainer, SFTConfig\nfrom transformers import Trainer, TrainingArguments\n\nFastVisionModel.for_training(model) # Enable for training!\n\ntrainer = Trainer(\n    model = model,\n    tokenizer = tokenizer,\n    data_collator = collate_fn, # Must use!\n    train_dataset = vqa_dataset,\n    args = TrainingArguments(\n        per_device_train_batch_size = 4,\n        gradient_accumulation_steps = 1,\n        warmup_steps = 5,\n        num_train_epochs = 1, # Set this instead of max_steps for full training runs\n        learning_rate = 2e-4,\n        fp16 = not is_bf16_supported(),\n        bf16 = is_bf16_supported(),\n        logging_steps = 10,\n        save_steps=1000,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = output_dir,\n        report_to = \"none\",     # For Weights and Biases\n        save_total_limit=2,\n        # You MUST put the below items for vision finetuning:\n        remove_unused_columns = False,\n        max_steps = max_steps\n\n\n    ),\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95_Nn-89DhsL","outputId":"dc1d8be2-ff56-4810-c6c4-ba346d34b263","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:21:29.240514Z","iopub.execute_input":"2025-05-13T19:21:29.241062Z","iopub.status.idle":"2025-05-13T19:21:29.291963Z","shell.execute_reply.started":"2025-05-13T19:21:29.241037Z","shell.execute_reply":"2025-05-13T19:21:29.291355Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2149036836.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# @title Show current memory stats\ngpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"2ejIt2xSNKKp","outputId":"3dc5b8d8-39cc-4629-efd0-c42a218312f0","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:11:30.562524Z","iopub.execute_input":"2025-05-13T19:11:30.563106Z","iopub.status.idle":"2025-05-13T19:11:30.568084Z","shell.execute_reply.started":"2025-05-13T19:11:30.563084Z","shell.execute_reply":"2025-05-13T19:11:30.567476Z"}},"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n6.494 GB of memory reserved.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# checkpoint_path = '/content/outputs/checkpoint-30'\n\ntrainer_stats = trainer.train(resume_from_checkpoint=checkpoint_path)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":501},"id":"yqxqAZ7KJ4oL","outputId":"5e2144e5-a7a3-4d6e-d49d-ee99e58396af","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T19:21:41.250787Z","iopub.execute_input":"2025-05-13T19:21:41.251253Z","iopub.status.idle":"2025-05-13T19:30:38.562326Z","shell.execute_reply.started":"2025-05-13T19:21:41.251232Z","shell.execute_reply":"2025-05-13T19:30:38.561182Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,217,194 | Num Epochs = 2 | Total steps = 304,298\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n \"-____-\"     Trainable parameters = 7,237,632/2,000,000,000 (0.36% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='247' max='304298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   247/304298 08:50 < 182:48:18, 0.46 it/s, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>9.413400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>9.341900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>6.225300</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>6.668300</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>8.848500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>6.560100</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>5.347400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>6.111400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>5.750500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>5.506900</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>5.524800</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>5.756400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>5.635600</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>6.420400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>6.291100</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>5.710600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>6.775200</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>6.111000</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>7.051100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>6.704100</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>6.536500</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>6.134500</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>5.885200</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>6.974700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3929128574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# checkpoint_path = '/content/outputs/checkpoint-30'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/compiler.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    305\u001b[0m             )\n\u001b[1;32m    306\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/cce.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_out)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mgrad_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mgrad_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"],"ename":"ZeroDivisionError","evalue":"division by zero","output_type":"error"}],"execution_count":40},{"cell_type":"code","source":"model.save_pretrained(f\"{model_dir}/lora_model\")  # Local saving\ntokenizer.save_pretrained(f\"{model_dir}/lora_model\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"298efe98-7038-4b57-fabc-695baf1e189e","trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:56:34.566971Z","iopub.status.idle":"2025-05-13T18:56:34.567249Z","shell.execute_reply.started":"2025-05-13T18:56:34.567131Z","shell.execute_reply":"2025-05-13T18:56:34.567144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}