{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "os.chdir('/home/danish/VR_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/VR_PROJECT/.vr_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set the GOOGLE_API_KEY in the environment first\n",
    "\n",
    "# Then configure the genai module with the API key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Now you can create the GenerativeModel instance\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_file = \"dataset/abo-listings/listings/metadata/listings_8.json\"\n",
    "image_metadata = pd.read_csv(\"dataset/abo-images-small/images/metadata/images.csv\")\n",
    "image_dataset_path = \"dataset/abo-images-small/images/small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output csv file\n",
    "output_file = f\"dataset/VQA-dataset/{listing_file.split('/')[-1].split('.')[0]}_VQA.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_lines(listing_file):\n",
    "    \"\"\"\n",
    "    Read the listing file and return a list of lines.\n",
    "    \"\"\"\n",
    "    with open(listing_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_product_json(product_json):\n",
    "        \"\"\"\n",
    "        Preprocess the product JSON to ensure it is in the correct format.\n",
    "        \"\"\"\n",
    "        list_of_keys_to_remove = ['main_image_id','node','other_image_id','spin_id','3dmodel_id']\n",
    "        # Convert JSON string to dictionary\n",
    "        product_dict = json.loads(product_json)\n",
    "        # Remove unnecessary keys\n",
    "        for key in list_of_keys_to_remove:\n",
    "            if key in product_dict:\n",
    "                del product_dict[key]\n",
    "        \n",
    "        # Convert dictionary to JSON string with indentation for better readability\n",
    "        return json.dumps(product_dict, indent=4)\n",
    "def prompt_for_product(product_json):\n",
    "        \"\"\"\n",
    "        Generate a prompt for the given product JSON.\n",
    "        \"\"\"\n",
    "        product_json = preprocess_product_json(product_json)\n",
    "        prompt = f\"\"\"\n",
    "        You are a QA dataset generator that creates short, factual, and human-readable question-answer pairs from Amazon product metadata and image. Each question must target a specific field from the metadata and be answerable with a **single word only**.\n",
    "\n",
    "        Below is the product metadata in structured format. Generate **5 to 10 diverse QA pairs**, where:\n",
    "        - Each question is clear and unambiguous.\n",
    "        - Each answer is strictly a **single word** (no phrases, no multi-word answers).\n",
    "        - Avoid repeating the same field.\n",
    "        - Prefer commonly relevant fields like: brand, bullet_points, color, material, product type, model name, style, fabric type, finish type, pattern, item shape, product description and color code.\n",
    "        - Questions should be such a way that they can be answered by looking at the image.\n",
    "        - The output should be in CSV format with columns: question, answer.\n",
    "\n",
    "        If a value is not meaningful or not present, skip that field. Ensure that QA pairs are diverse and aligned with the data provided.\n",
    "\n",
    "        ---\n",
    "        {product_json}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_paths(image_ids):\n",
    "    \"\"\"\n",
    "    Get the paths of images based on their IDs.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    for image_id in image_ids:\n",
    "        image_path = image_metadata[image_metadata['image_id'] == image_id]['path'].values\n",
    "        if len(image_path) > 0:\n",
    "            if os.path.exists(f\"{image_dataset_path}/{image_path[0]}\"):\n",
    "                image_paths.append(f\"{image_path[0]}\")\n",
    "    if len(image_paths) > 2:\n",
    "        image_paths = image_paths[:2]\n",
    "    return image_paths\n",
    "\n",
    "def generate_VQA(prompt, image_path):\n",
    "    img = Image.open(f\"{image_dataset_path}/{image_path}\")\n",
    "    img = img.convert(\"RGB\")\n",
    "    # Generate the VQA using the model\n",
    "    response = model.generate_content([prompt, img])\n",
    "    # Extract the generated text from the response\n",
    "    generated_text = response.text\n",
    "    #read csv from the generated text\n",
    "    csv_data = pd.read_csv(StringIO(generated_text.strip(\"`\").replace(\"csv\\n\", \"\", 1).strip()))\n",
    "    return csv_data\n",
    "\n",
    "def get_VQA_for_product(product_json):\n",
    "    df = pd.DataFrame(columns=[\"image_path\",\"question\", \"answer\"])\n",
    "    list_of_image_ids = []\n",
    "    \n",
    "    prompt = prompt_for_product(product_json)\n",
    "    product_dict = json.loads(product_json)\n",
    "    if \"main_image_id\" in product_dict.keys():\n",
    "        list_of_image_ids.append(product_dict['main_image_id'])\n",
    "    if \"other_image_id\" in product_dict.keys():\n",
    "        # Check if the key exists in the dictionary\n",
    "        if isinstance(product_dict['other_image_id'], list):\n",
    "            # If it's a list, extend it to the list_of_image_ids\n",
    "            list_of_image_ids.extend(product_dict['other_image_id'])\n",
    "        else:\n",
    "            # If it's not a list, append it directly\n",
    "            list_of_image_ids.append(product_dict['other_image_id'])\n",
    "    image_paths = get_images_paths(list_of_image_ids)\n",
    "\n",
    "    # print(f\"Image paths: {image_paths}\")\n",
    "    # Generate the VQA using the model\n",
    "    if len(image_paths) == 0:\n",
    "        print(\"No images found for this product.\")\n",
    "        return df\n",
    "    for image_path in image_paths:\n",
    "        # print(f\"Generating VQA for image: {image_path}\")\n",
    "        # Generate the VQA using the model\n",
    "        csv_data = generate_VQA(prompt, image_path)\n",
    "        # Append the generated data to the dataframe\n",
    "        csv_data['image_path'] = image_path\n",
    "        df = pd.concat([df, csv_data], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/VQA-dataset/listings_8_VQA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7101/9232 [02:20<1:42:37,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7171/9232 [05:26<1:34:06,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for this product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7201/9232 [06:58<1:52:24,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 7251/9232 [09:28<1:29:33,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7301/9232 [12:00<1:43:43,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7360/9232 [15:01<1:40:26,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for this product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 7401/9232 [16:51<1:13:27,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 7451/9232 [19:33<1:29:01,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 7501/9232 [22:06<1:37:49,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 7551/9232 [24:27<1:27:29,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 7601/9232 [26:42<1:30:49,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 7651/9232 [29:15<48:24,  1.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 7701/9232 [31:33<1:14:23,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 7751/9232 [33:40<1:03:33,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 7801/9232 [36:08<56:56,  2.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 7901/9232 [41:04<1:09:55,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 7951/9232 [43:25<1:14:47,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 7976/9232 [44:29<56:11,  2.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for this product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8001/9232 [45:40<1:15:02,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8051/9232 [48:04<55:23,  2.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8101/9232 [50:14<39:09,  2.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8151/9232 [52:33<57:18,  3.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8201/9232 [54:38<41:42,  2.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8301/9232 [59:17<32:30,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 8351/9232 [1:01:47<50:48,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 8401/9232 [1:04:04<38:35,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 8551/9232 [1:11:08<24:22,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 8601/9232 [1:13:26<26:37,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 8651/9232 [1:15:52<25:49,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 8701/9232 [1:18:23<31:16,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 8751/9232 [1:20:36<29:38,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 8801/9232 [1:23:00<16:19,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 8851/9232 [1:25:24<19:40,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 8882/9232 [1:26:56<18:32,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for this product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 8901/9232 [1:28:21<36:24,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 8951/9232 [1:30:51<15:24,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 8950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9001/9232 [1:33:58<14:14,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 9101/9232 [1:38:39<04:47,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9151/9232 [1:40:59<02:59,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9201/9232 [1:43:13<01:31,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9232/9232 [1:44:39<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQA dataset saved to dataset/VQA-dataset/listings_8_VQA.csv\n",
      "Progress saved at line 9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "print(output_file)\n",
    "if not os.path.exists(output_file):\n",
    "    print(f\"Output file {output_file} does not exist. Creating a new one.\")\n",
    "    output_df = pd.DataFrame(columns=[\"image_path\",\"question\", \"answer\"])\n",
    "else:\n",
    "    output_df = pd.read_csv(output_file)\n",
    "\n",
    "\n",
    "lines = get_listing_lines(listing_file)\n",
    "\n",
    "# subset_lines = lines[556:]  # to process a subset of lines\n",
    "start_index = 7051\n",
    "try:\n",
    "    for i in tqdm(range(start_index, len(lines)), initial=start_index, total=len(lines)):\n",
    "        line = lines[i]\n",
    "        if \"\\\"en_\" not in line:\n",
    "            continue\n",
    "        try:\n",
    "            df = get_VQA_for_product(line)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line {i}: {e}\")\n",
    "            if \"Resource has been exhausted\" in str(e):\n",
    "                print(\"Resource has been exhausted. Please try again later.\")\n",
    "                time.sleep(300)\n",
    "                try:\n",
    "                    df = get_VQA_for_product(line)\n",
    "                except Exception as e:\n",
    "                    time.sleep(900)\n",
    "                    df = get_VQA_for_product(line)\n",
    "            else:\n",
    "                continue\n",
    "        output_df = pd.concat([output_df, df], ignore_index=True)\n",
    "        if i % 50 == 0:\n",
    "            # Save the output DataFrame to a CSV file every 50 iterations\n",
    "            output_df.to_csv(output_file, index=False)\n",
    "            print(f\"Progress saved at line {i}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Handle the exception as needed\n",
    "    pass\n",
    "# Save the output DataFrame to a CSV file\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"VQA dataset saved to {output_file}\") \n",
    "print(f\"Progress saved at line {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
