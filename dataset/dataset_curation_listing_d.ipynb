{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "os.chdir('/home/danish/VR_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/VR_PROJECT/.vr_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set the GOOGLE_API_KEY in the environment first\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBwIwHp09emTK7ci1RI-eYNuX8NU1LJJGI\"\n",
    "\n",
    "# Then configure the genai module with the API key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Now you can create the GenerativeModel instance\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_file = \"dataset/abo-listings/listings/metadata/listings_d.json\"\n",
    "image_metadata = pd.read_csv(\"dataset/abo-images-small/images/metadata/images.csv\")\n",
    "image_dataset_path = \"dataset/abo-images-small/images/small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output csv file\n",
    "output_file = f\"dataset/VQA-dataset/{listing_file.split('/')[-1].split('.')[0]}_VQA.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_lines(listing_file):\n",
    "    \"\"\"\n",
    "    Read the listing file and return a list of lines.\n",
    "    \"\"\"\n",
    "    with open(listing_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_product_json(product_json):\n",
    "        \"\"\"\n",
    "        Preprocess the product JSON to ensure it is in the correct format.\n",
    "        \"\"\"\n",
    "        list_of_keys_to_remove = ['main_image_id','node','other_image_id','spin_id','3dmodel_id']\n",
    "        # Convert JSON string to dictionary\n",
    "        product_dict = json.loads(product_json)\n",
    "        # Remove unnecessary keys\n",
    "        for key in list_of_keys_to_remove:\n",
    "            if key in product_dict:\n",
    "                del product_dict[key]\n",
    "        \n",
    "        # Convert dictionary to JSON string with indentation for better readability\n",
    "        return json.dumps(product_dict, indent=4)\n",
    "def prompt_for_product(product_json):\n",
    "        \"\"\"\n",
    "        Generate a prompt for the given product JSON.\n",
    "        \"\"\"\n",
    "        product_json = preprocess_product_json(product_json)\n",
    "        prompt = f\"\"\"\n",
    "        You are a QA dataset generator that creates short, factual, and human-readable question-answer pairs from Amazon product metadata and image. Each question must target a specific field from the metadata and be answerable with a **single word only**.\n",
    "\n",
    "        Below is the product metadata in structured format. Generate **5 to 10 diverse QA pairs**, where:\n",
    "        - Each question is clear and unambiguous.\n",
    "        - Each answer is strictly a **single word** (no phrases, no multi-word answers).\n",
    "        - Avoid repeating the same field.\n",
    "        - Prefer commonly relevant fields like: brand, bullet_points, color, material, product type, model name, style, fabric type, finish type, pattern, item shape, product description and color code.\n",
    "        - Questions should be such a way that they can be answered by looking at the image.\n",
    "        - The output should be in CSV format with columns: question, answer.\n",
    "\n",
    "        If a value is not meaningful or not present, skip that field. Ensure that QA pairs are diverse and aligned with the data provided.\n",
    "\n",
    "        ---\n",
    "        {product_json}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_paths(image_ids):\n",
    "    \"\"\"\n",
    "    Get the paths of images based on their IDs.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    for image_id in image_ids:\n",
    "        image_path = image_metadata[image_metadata['image_id'] == image_id]['path'].values\n",
    "        if len(image_path) > 0:\n",
    "            if os.path.exists(f\"{image_dataset_path}/{image_path[0]}\"):\n",
    "                image_paths.append(f\"{image_path[0]}\")\n",
    "    return image_paths\n",
    "\n",
    "def generate_VQA(prompt, image_path):\n",
    "    img = Image.open(f\"{image_dataset_path}/{image_path}\")\n",
    "    img = img.convert(\"RGB\")\n",
    "    # Generate the VQA using the model\n",
    "    response = model.generate_content([prompt, img])\n",
    "    # Extract the generated text from the response\n",
    "    generated_text = response.text\n",
    "    #read csv from the generated text\n",
    "    csv_data = pd.read_csv(StringIO(generated_text.strip(\"`\").replace(\"csv\\n\", \"\", 1).strip()))\n",
    "    return csv_data\n",
    "\n",
    "def get_VQA_for_product(product_json):\n",
    "    df = pd.DataFrame(columns=[\"image_path\",\"question\", \"answer\"])\n",
    "    list_of_image_ids = []\n",
    "    \n",
    "    prompt = prompt_for_product(product_json)\n",
    "    product_dict = json.loads(product_json)\n",
    "    if \"main_image_id\" in product_dict.keys():\n",
    "        list_of_image_ids.append(product_dict['main_image_id'])\n",
    "    if \"other_image_id\" in product_dict.keys():\n",
    "        # Check if the key exists in the dictionary\n",
    "        if isinstance(product_dict['other_image_id'], list):\n",
    "            # If it's a list, extend it to the list_of_image_ids\n",
    "            list_of_image_ids.extend(product_dict['other_image_id'])\n",
    "        else:\n",
    "            # If it's not a list, append it directly\n",
    "            list_of_image_ids.append(product_dict['other_image_id'])\n",
    "    image_paths = get_images_paths(list_of_image_ids)\n",
    "\n",
    "    # print(f\"Image paths: {image_paths}\")\n",
    "    # Generate the VQA using the model\n",
    "    if len(image_paths) == 0:\n",
    "        print(\"No images found for this product.\")\n",
    "        return df\n",
    "    for image_path in image_paths:\n",
    "        # print(f\"Generating VQA for image: {image_path}\")\n",
    "        # Generate the VQA using the model\n",
    "        csv_data = generate_VQA(prompt, image_path)\n",
    "        # Append the generated data to the dataframe\n",
    "        csv_data['image_path'] = image_path\n",
    "        df = pd.concat([df, csv_data], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/VQA-dataset/listings_d_VQA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 525/9232 [00:46<26:43:23, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 525: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 535/9232 [27:15<65:55:27, 27.29s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 535: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 545/9232 [38:37<57:29:15, 23.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 545: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 546/9232 [48:48<430:13:51, 178.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 546: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 547/9232 [59:05<719:50:30, 298.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 550: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 551/9232 [1:09:17<505:44:45, 209.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 578/9232 [1:13:32<21:38:36,  9.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 579: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 580/9232 [1:23:43<314:36:12, 130.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 580: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 584/9232 [1:34:37<272:03:31, 113.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 584: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 601/9232 [2:02:37<36:33:39, 15.25s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 600\n",
      "Error processing line 601: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 603/9232 [2:12:49<267:08:21, 111.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 603: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 625/9232 [2:27:11<35:52:10, 15.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 625: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 701/9232 [2:48:27<27:17:55, 11.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 704/9232 [2:49:06<30:36:08, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 704: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 706/9232 [2:59:24<321:08:22, 135.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 706: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 722/9232 [3:27:24<34:02:00, 14.40s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for this product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 723/9232 [3:27:26<25:14:29, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 723: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 736/9232 [3:38:44<35:30:07, 15.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 737: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 742/9232 [4:04:24<303:02:31, 128.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 742: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 743/9232 [4:14:39<519:15:41, 220.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 743: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 743/9232 [4:39:43<178:16:24, 75.60s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429 Resource has been exhausted (e.g. check quota).\n",
      "VQA dataset saved to dataset/VQA-dataset/listings_d_VQA.csv\n",
      "Progress saved at line 743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "print(output_file)\n",
    "if not os.path.exists(output_file):\n",
    "    print(f\"Output file {output_file} does not exist. Creating a new one.\")\n",
    "    output_df = pd.DataFrame(columns=[\"image_path\",\"question\", \"answer\"])\n",
    "else:\n",
    "    output_df = pd.read_csv(output_file)\n",
    "\n",
    "\n",
    "lines = get_listing_lines(listing_file)\n",
    "\n",
    "# subset_lines = lines[556:]  # to process a subset of lines\n",
    "start_index = 743\n",
    "try:\n",
    "    for i in tqdm(range(start_index, len(lines)), initial=start_index, total=len(lines)):\n",
    "        line = lines[i]\n",
    "        if \"\\\"en_\" not in line:\n",
    "            continue\n",
    "        try:\n",
    "            df = get_VQA_for_product(line)\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line {i}: {e}\")\n",
    "            if \"Resource has been exhausted\" in str(e):\n",
    "                print(\"Resource has been exhausted. Please try again later.\")\n",
    "                time.sleep(600)\n",
    "                try:\n",
    "                    df = get_VQA_for_product(line)\n",
    "                except Exception as e:\n",
    "                    time.sleep(900)\n",
    "                    df = get_VQA_for_product(line)\n",
    "            else:\n",
    "                continue\n",
    "        output_df = pd.concat([output_df, df], ignore_index=True)\n",
    "        if i % 50 == 0:\n",
    "            # Save the output DataFrame to a CSV file every 50 iterations\n",
    "            output_df.to_csv(output_file, index=False)\n",
    "            print(f\"Progress saved at line {i}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Handle the exception as needed\n",
    "    pass\n",
    "# Save the output DataFrame to a CSV file\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"VQA dataset saved to {output_file}\") \n",
    "print(f\"Progress saved at line {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
