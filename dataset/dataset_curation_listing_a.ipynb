{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "os.chdir('/home/danish/VR_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/VR_PROJECT/.vr_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set the GOOGLE_API_KEY in the environment first\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAV7jxsMgGCSGCsI0FqHTds47SVYAaDtJQ\"\n",
    "\n",
    "# Then configure the genai module with the API key\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Now you can create the GenerativeModel instance\n",
    "model = genai.GenerativeModel('gemini-2.0-flash-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_file = \"dataset/abo-listings/listings/metadata/listings_a.json\"\n",
    "image_metadata = pd.read_csv(\"dataset/abo-images-small/images/metadata/images.csv\")\n",
    "image_dataset_path = \"dataset/abo-images-small/images/small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output csv file\n",
    "output_file = f\"dataset/VQA-dataset/{listing_file.split('/')[-1].split('.')[0]}_VQA.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listing_lines(listing_file):\n",
    "    \"\"\"\n",
    "    Read the listing file and return a list of lines.\n",
    "    \"\"\"\n",
    "    with open(listing_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_product_json(product_json):\n",
    "        \"\"\"\n",
    "        Preprocess the product JSON to ensure it is in the correct format.\n",
    "        \"\"\"\n",
    "        list_of_keys_to_remove = ['main_image_id','node','other_image_id','spin_id','3dmodel_id']\n",
    "        # Convert JSON string to dictionary\n",
    "        product_dict = json.loads(product_json)\n",
    "        # Remove unnecessary keys\n",
    "        for key in list_of_keys_to_remove:\n",
    "            if key in product_dict:\n",
    "                del product_dict[key]\n",
    "        \n",
    "        # Convert dictionary to JSON string with indentation for better readability\n",
    "        return json.dumps(product_dict, indent=4)\n",
    "def prompt_for_product(product_json):\n",
    "        \"\"\"\n",
    "        Generate a prompt for the given product JSON.\n",
    "        \"\"\"\n",
    "        product_json = preprocess_product_json(product_json)\n",
    "        prompt = f\"\"\"\n",
    "        You are a QA dataset generator that creates short, factual, and human-readable question-answer pairs from Amazon product metadata and image. Each question must target a specific field from the metadata and be answerable with a **single word only**.\n",
    "\n",
    "        Below is the product metadata in structured format. Generate **5 to 10 diverse QA pairs**, where:\n",
    "        - Each question is clear and unambiguous.\n",
    "        - Each answer is strictly a **single word** (no phrases, no multi-word answers).\n",
    "        - Avoid repeating the same field.\n",
    "        - Prefer commonly relevant fields like: brand, bullet_points, color, material, product type, model name, style, fabric type, finish type, pattern, item shape, product description and color code.\n",
    "        - Questions should be such a way that they can be answered by looking at the image.\n",
    "        - The output should be in CSV format with columns: question, answer.\n",
    "\n",
    "        If a value is not meaningful or not present, skip that field. Ensure that QA pairs are diverse and aligned with the data provided.\n",
    "\n",
    "        ---\n",
    "        {product_json}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_paths(image_ids):\n",
    "    \"\"\"\n",
    "    Get the paths of images based on their IDs.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    for image_id in image_ids:\n",
    "        image_path = image_metadata[image_metadata['image_id'] == image_id]['path'].values\n",
    "        if len(image_path) > 0:\n",
    "            if os.path.exists(f\"{image_dataset_path}/{image_path[0]}\"):\n",
    "                image_paths.append(f\"{image_path[0]}\")\n",
    "    return image_paths\n",
    "\n",
    "def generate_VQA(prompt, image_path):\n",
    "    img = Image.open(f\"{image_dataset_path}/{image_path}\")\n",
    "    img = img.convert(\"RGB\")\n",
    "    # Generate the VQA using the model\n",
    "    response = model.generate_content([prompt, img])\n",
    "    # Extract the generated text from the response\n",
    "    generated_text = response.text\n",
    "    #read csv from the generated text\n",
    "    csv_data = pd.read_csv(StringIO(generated_text.strip(\"`\").replace(\"csv\\n\", \"\", 1).strip()))\n",
    "    return csv_data\n",
    "\n",
    "def get_VQA_for_product(product_json):\n",
    "    df = pd.DataFrame(columns=[\"image_path\",\"question\", \"answer\"])\n",
    "    list_of_image_ids = []\n",
    "    \n",
    "    prompt = prompt_for_product(product_json)\n",
    "    product_dict = json.loads(product_json)\n",
    "    if \"main_image_id\" in product_dict.keys():\n",
    "        list_of_image_ids.append(product_dict['main_image_id'])\n",
    "    if \"other_image_id\" in product_dict.keys():\n",
    "        # Check if the key exists in the dictionary\n",
    "        if isinstance(product_dict['other_image_id'], list):\n",
    "            # If it's a list, extend it to the list_of_image_ids\n",
    "            list_of_image_ids.extend(product_dict['other_image_id'])\n",
    "        else:\n",
    "            # If it's not a list, append it directly\n",
    "            list_of_image_ids.append(product_dict['other_image_id'])\n",
    "    image_paths = get_images_paths(list_of_image_ids)\n",
    "\n",
    "    # print(f\"Image paths: {image_paths}\")\n",
    "    # Generate the VQA using the model\n",
    "    if len(image_paths) == 0:\n",
    "        print(\"No images found for this product.\")\n",
    "        return df\n",
    "    for image_path in image_paths:\n",
    "        # print(f\"Generating VQA for image: {image_path}\")\n",
    "        # Generate the VQA using the model\n",
    "        csv_data = generate_VQA(prompt, image_path)\n",
    "        # Append the generated data to the dataframe\n",
    "        csv_data['image_path'] = image_path\n",
    "        df = pd.concat([df, csv_data], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/VQA-dataset/listings_a_VQA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1751/9232 [00:21<44:20:48, 21.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 1750\n",
      "Error processing line 1751: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1756/9232 [06:17<70:39:41, 34.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1756: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1785/9232 [16:15<14:30:42,  7.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1785: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1801/9232 [24:36<36:22:57, 17.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1806/9232 [25:24<22:28:43, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for this product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1819/9232 [27:26<23:43:08, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1819: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1820/9232 [32:50<186:18:35, 90.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1820: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1833/9232 [39:32<21:10:23, 10.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1833: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1850/9232 [47:06<20:47:50, 10.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1850: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1851/9232 [52:44<216:05:50, 105.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1884/9232 [57:20<17:35:52,  8.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1884: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1897/9232 [1:04:19<19:58:58,  9.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1897: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1898/9232 [1:24:44<577:30:33, 283.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1898: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1901/9232 [1:30:04<352:07:02, 172.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1938/9232 [1:36:21<24:34:56, 12.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1939: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1951/9232 [1:43:29<20:22:57, 10.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1968/9232 [1:46:08<16:45:45,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1968: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1971/9232 [1:51:56<99:35:02, 49.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1972: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2001/9232 [2:00:23<11:50:13,  5.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2017/9232 [2:02:02<11:42:32,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2018: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2051/9232 [2:11:32<20:32:25, 10.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2076/9232 [2:14:20<13:18:32,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2076: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2112/9232 [2:24:55<19:02:49,  9.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2112: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2115/9232 [2:30:25<102:54:05, 52.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2115: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2151/9232 [2:39:56<15:01:12,  7.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 2176/9232 [2:44:01<17:06:54,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2176: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 2192/9232 [2:51:42<23:01:36, 11.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2192: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2201/9232 [3:13:19<78:18:14, 40.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2224/9232 [3:17:26<16:56:45,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2224: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2251/9232 [3:27:01<15:32:23,  8.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved at line 2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2253/9232 [3:27:22<17:54:27,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2253: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2274/9232 [3:51:06<22:29:26, 11.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 2274: 429 Resource has been exhausted (e.g. check quota).\n",
      "Resource has been exhausted. Please try again later.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "print(output_file)\n",
    "if not os.path.exists(output_file):\n",
    "    print(f\"Output file {output_file} does not exist. Creating a new one.\")\n",
    "    output_df = pd.DataFrame(columns=[\"image_path\",\"question\", \"answer\"])\n",
    "else:\n",
    "    output_df = pd.read_csv(output_file)\n",
    "\n",
    "\n",
    "lines = get_listing_lines(listing_file)\n",
    "\n",
    "# subset_lines = lines[556:]  # to process a subset of lines\n",
    "start_index = 1750\n",
    "try:\n",
    "    for i in tqdm(range(start_index, len(lines)), initial=start_index, total=len(lines)):\n",
    "        line = lines[i]\n",
    "        if \"\\\"en_\" not in line:\n",
    "            continue\n",
    "        try:\n",
    "            df = get_VQA_for_product(line)\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line {i}: {e}\")\n",
    "            if \"Resource has been exhausted\" in str(e):\n",
    "                print(\"Resource has been exhausted. Please try again later.\")\n",
    "                time.sleep(300)\n",
    "                try:\n",
    "                    df = get_VQA_for_product(line)\n",
    "                except Exception as e:\n",
    "                    time.sleep(900)\n",
    "                    df = get_VQA_for_product(line)\n",
    "            else:\n",
    "                continue\n",
    "        output_df = pd.concat([output_df, df], ignore_index=True)\n",
    "        if i % 50 == 0:\n",
    "            # Save the output DataFrame to a CSV file every 50 iterations\n",
    "            output_df.to_csv(output_file, index=False)\n",
    "            print(f\"Progress saved at line {i}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # Handle the exception as needed\n",
    "    pass\n",
    "# Save the output DataFrame to a CSV file\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"VQA dataset saved to {output_file}\") \n",
    "print(f\"Progress saved at line {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
